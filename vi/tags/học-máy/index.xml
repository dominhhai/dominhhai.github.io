<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Học Máy on Hai&#39;s Blog</title><link>https://dominhhai.github.io/vi/tags/h%E1%BB%8Dc-m%C3%A1y/</link><description>Recent content in Học Máy on Hai&#39;s Blog</description><generator>Hugo -- gohugo.io</generator><language>vi</language><lastBuildDate>Sun, 08 Jul 2018 10:20:14 +0900</lastBuildDate><atom:link href="https://dominhhai.github.io/vi/tags/h%E1%BB%8Dc-m%C3%A1y/index.xml" rel="self" type="application/rss+xml"/><item><title>[Talk] Slide về RNNs, LSTM, GRU</title><link>https://dominhhai.github.io/vi/2018/07/talk-rnn/</link><pubDate>Sun, 08 Jul 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/07/talk-rnn/</guid><description>&lt;p&gt;Dưới đấy là slide giới thiệu về RNNs, LSTM, GRU tại &lt;a href=&#34;https://www.facebook.com/events/1772695682776739/&#34;&gt;Tokyo ML Event&lt;/a&gt; hôm chủ nhật 08/07/2018 vừa qua. Tiện đây, blog mình có thêm mục &lt;strong&gt;&lt;a href=&#34;https://dominhhai.github.io/vi/talk/&#34;&gt;Chém gió&lt;/a&gt;&lt;/strong&gt; lưu trữ lại các slide trình bày của mình tại các hội nhóm.&lt;/p&gt;</description></item><item><title>[NN] Mạng quá khớp - Overfitting</title><link>https://dominhhai.github.io/vi/2018/05/nn-overfitting/</link><pubDate>Mon, 28 May 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/05/nn-overfitting/</guid><description>&lt;p&gt;Cũng như các bài toán ML khác, mạng NN hoàn toàn có thể bị quá khớp nếu kích cỡ lớn quá mức cần thiết. Nên khi cài đặt mạng NN, người ta thường cài thêm các phương pháp như &lt;em&gt;chính quy hoá&lt;/em&gt;, &lt;em&gt;bỏ nút mạng&lt;/em&gt;&amp;hellip; nhằm giảm được vấn đề này.&lt;/p&gt;</description></item><item><title>[NN] Về lan truyền ngược - Backpropagation</title><link>https://dominhhai.github.io/vi/2018/04/nn-bp/</link><pubDate>Fri, 27 Apr 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/04/nn-bp/</guid><description>&lt;p&gt;Bài viết này được dịch lại từ &lt;a href=&#34;https://colah.github.io/posts/2015-08-Backprop/&#34;&gt;bài của anh Christopher Olah&lt;/a&gt; bởi anh ấy trình bày rất chi tiết và cực dễ hiểu nên mình không viết lại làm gì cho phí công nữa.
Nội dung của bài viết này không phải về chi tiết giải thuật lan truyền ngược mà viết về nguyên lý cơ bản của giải thuật này. Nếu bạn cần xem chi tiết giải thuật được thực hiện ra sao thì có thể đọc &lt;a href=&#34;https://dominhhai.github.io/vi/2018/04/nn-intro/#5-lan-truyền-ngược-và-đạo-hàm&#34;&gt;bài viết trước của tôi&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>[NN] Cài đặt mạng NN</title><link>https://dominhhai.github.io/vi/2018/04/nn-implement/</link><pubDate>Thu, 26 Apr 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/04/nn-implement/</guid><description>&lt;p&gt;Bài viết này sẽ tập trung vào việc cài đặt mạng NN để nhận dạng số và đưa ra một số mẹo để thu được kết quả tốt khi làm việc với mạng NN. Nếu bạn chưa có cái nhìn tổng quan về mặt lý thuyết của mạng NN thì tôi nghĩ rằng bạn nên đọc &lt;a href=&#34;https://dominhhai.github.io/vi/2018/04/nn-intro/&#34;&gt;bài viết trước&lt;/a&gt; của tôi để có thể dễ dàng hiểu bài này hơn.&lt;/p&gt;</description></item><item><title>[NN] Mạng nơ-ron nhân tạo - Neural Networks</title><link>https://dominhhai.github.io/vi/2018/04/nn-intro/</link><pubDate>Mon, 23 Apr 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/04/nn-intro/</guid><description>&lt;p&gt;Mạng nơ-ron nhân tạo (&lt;em&gt;Neural Network&lt;/em&gt; - &lt;strong&gt;NN&lt;/strong&gt;) là một mô hình lập trình rất đẹp lấy cảm hứng từ mạng nơ-ron thần kinh. Kết hợp với các kĩ thuật học sâu (&lt;em&gt;Deep Learning&lt;/em&gt; - &lt;strong&gt;DL&lt;/strong&gt;), NN đang trở thành một công cụ rất mạnh mẽ mang lại hiệu quả tốt nhất cho nhiều bài toán khó như nhận dạng ảnh, giọng nói hay xử lý ngôn ngữ tự nhiên.&lt;/p&gt;</description></item><item><title>[ML] Support Vector Machine - SVM</title><link>https://dominhhai.github.io/vi/2018/03/ml-svm/</link><pubDate>Thu, 22 Mar 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/03/ml-svm/</guid><description>&lt;p&gt;Support Vector Machine - &lt;strong&gt;SVM&lt;/strong&gt; là một phương pháp học có giám sát trong các mô hình nhận dạng mẫu. Nó không chỉ hoạt động tốt với các dữ liệu được phân tách tuyến tính mà còn tốt với cả dữ liệu phân tách phi tuyến. Với nhiều bài toán, SVM mang lại kết quả tốt như mạng nơ-ron với hiệu quả sử dụng tài nguyên tốt hơn hẳn.&lt;/p&gt;</description></item><item><title>[ML] Phân cụm K-Means (K-Means clustering)</title><link>https://dominhhai.github.io/vi/2018/02/ml-kmeans/</link><pubDate>Mon, 05 Feb 2018 16:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/02/ml-kmeans/</guid><description>&lt;p&gt;Với bài toán học phi giám sát, làm sao ta có thể sắp xếp dữ liệu vào các nhóm tương ứng? Bài viết này sẽ trình bày một phương pháp đơn giản để có thể thực hiện được việc này là phương pháp phân cụm K-Means.&lt;/p&gt;</description></item><item><title>[ML] Hồi quy logistic (Logistic Regression)</title><link>https://dominhhai.github.io/vi/2017/12/ml-logistic-regression/</link><pubDate>Thu, 28 Dec 2017 11:19:53 +0900</pubDate><guid>https://dominhhai.github.io/vi/2017/12/ml-logistic-regression/</guid><description>&lt;p&gt;Trong các phần trước ta đã tìm hiểu về phương pháp hồi quy tuyến tính để dự đoán đầu ra liên tục, phần này ta sẽ tìm hiểu thêm một thuật toán nữa trong học có giám sát là &lt;strong&gt;hồi quy logistic&lt;/strong&gt; (&lt;em&gt;Logistic Regression&lt;/em&gt;) nhằm mục đính phân loại dữ liệu.&lt;/p&gt;</description></item><item><title>[ML] Cân bằng phương sai và độ lệch</title><link>https://dominhhai.github.io/vi/2017/12/20171226-ml-bias-variance-tradeoff/</link><pubDate>Tue, 26 Dec 2017 14:48:36 +0900</pubDate><guid>https://dominhhai.github.io/vi/2017/12/20171226-ml-bias-variance-tradeoff/</guid><description>&lt;p&gt;Bài này sẽ tập trung vào lý thuyết đằng sau các lỗi mô hình đã trình bày ở &lt;a href=&#34;https://dominhhai.github.io/vi/2017/12/ml-overfitting/&#34;&gt;bài viết trước&lt;/a&gt;. Việc hiểu lý thuyết này giúp ta có được cái nhìn toàn vẹn hơn về lỗi mô hình và cơ sở đánh giá lỗi.&lt;/p&gt;</description></item><item><title>[ML] Mô hình quá khớp (Overfitting)</title><link>https://dominhhai.github.io/vi/2017/12/ml-overfitting/</link><pubDate>Mon, 25 Dec 2017 08:45:04 +0900</pubDate><guid>https://dominhhai.github.io/vi/2017/12/ml-overfitting/</guid><description>&lt;p&gt;Lỗi ước lượng tham số có thể được chia thành 2 loại là &lt;strong&gt;khớp quá&lt;/strong&gt; (&lt;em&gt;over-fitting&lt;/em&gt;) và &lt;strong&gt;chưa khớp&lt;/strong&gt; (&lt;em&gt;under-fitting&lt;/em&gt;) với tập huấn luyện. Trong bài này sẽ nói về cách theo dõi và hạn chế các lỗi này ra sao. Trọng tâm của bài này sẽ tập trung chủ yếu vào kĩ thuật &lt;strong&gt;chính quy hoá&lt;/strong&gt; (&lt;em&gt;regularization&lt;/em&gt;) để giải quyết vấn đề khớp quá của tham số.&lt;/p&gt;</description></item><item><title>[ML] Tối ưu hàm lỗi với Gradient Descent</title><link>https://dominhhai.github.io/vi/2017/12/ml-gd/</link><pubDate>Fri, 22 Dec 2017 08:45:04 +0900</pubDate><guid>https://dominhhai.github.io/vi/2017/12/ml-gd/</guid><description>&lt;p&gt;Mặc dù sử dụng công thức chuẩn để tìm tham số là có thể thực hiện được, nhưng với tập dữ liệu lớn nhiều chiều trong thực tế thì với máy tính lại không thể thực hiện được do các ràng buộc của bộ nhớ cũng như khả năng tính toán. Chưa kể với nhiều bài toán việc giải được đạo hàm để tìm ra công thức chuẩn là rất khó khăn. Nên trong thực tế giải thuật thay thế là &lt;strong&gt;Gradient Descent&lt;/strong&gt; thường được sử dụng.&lt;/p&gt;</description></item><item><title>[ML] MLE của hồi quy tuyến tính</title><link>https://dominhhai.github.io/vi/2017/12/ml-linear-regression-mle/</link><pubDate>Thu, 21 Dec 2017 12:28:26 +0900</pubDate><guid>https://dominhhai.github.io/vi/2017/12/ml-linear-regression-mle/</guid><description>&lt;p&gt;Như bài viết trước đã đề cập tới phương pháp ước lượng tham số bằng công thức chuẩn cho thuật toán hồi quy tuyến tính $\hat\theta=(\Phi^{\intercal}\Phi)^{-1}\Phi^{\intercal}\mathbf{y}$ bằng cách lấy đạo hàm hàm lỗi (&lt;em&gt;mean squared error&lt;/em&gt;). Có thể bạn sẽ nghi ngờ về mức độ tin cậy thống kê của phương pháp ước lượng đó, nên bài viết này sẽ phân tích lý thuyết xác suất ước lượng bằng &lt;a href=&#34;https://dominhhai.github.io/vi/2017/10/sampling-parameters-estimation/#2-2-mle&#34;&gt;MLE (&lt;em&gt;Maximum Likelihood Esitmation&lt;/em&gt;)&lt;/a&gt; xem sao.&lt;/p&gt;</description></item><item><title>[ML] Hồi quy tuyến tính (Linear Regression)</title><link>https://dominhhai.github.io/vi/2017/12/ml-linear-regression/</link><pubDate>Tue, 19 Dec 2017 12:54:51 +0900</pubDate><guid>https://dominhhai.github.io/vi/2017/12/ml-linear-regression/</guid><description>&lt;p&gt;Học có giám sát (&lt;em&gt;Supervised Learning&lt;/em&gt;) được chia ra làm 2 dạng lớn là &lt;strong&gt;hồi quy&lt;/strong&gt; (&lt;em&gt;regression&lt;/em&gt;) và &lt;strong&gt;phân loại&lt;/strong&gt; (&lt;em&gt;classification&lt;/em&gt;) dựa trên tập dữ liệu mẫu - tập huấn luyện (&lt;em&gt;training data&lt;/em&gt;). Với bài đầu tiên này ta sẽ bắt đầu bằng bài toán hồi quy mà cụ thể là hồi quy tuyến tính (&lt;em&gt;linear regression&lt;/em&gt;).&lt;/p&gt;</description></item><item><title>Pattern Recognition and Machine Learning</title><link>https://dominhhai.github.io/vi/2017/12/ml-prml/</link><pubDate>Tue, 12 Dec 2017 16:36:56 +0900</pubDate><guid>https://dominhhai.github.io/vi/2017/12/ml-prml/</guid><description>&lt;p&gt;Được coi là sách giáo khoa cho những người làm học máy, cuốn sách này viết về các giải thuật và lý thuyết xây dựng các giải thuật nhận dạng mẫu và học máy. Tuy nhiên lúc mới đọc thì thấy khá khó nhằn nên tôi đã tìm hiểu độ khó các phần đề biết đường mà đọc.&lt;/p&gt;</description></item><item><title>[ML] Học máy là gì?</title><link>https://dominhhai.github.io/vi/2017/12/ml-intro/</link><pubDate>Fri, 08 Dec 2017 16:31:37 +0900</pubDate><guid>https://dominhhai.github.io/vi/2017/12/ml-intro/</guid><description>&lt;p&gt;Thời gian gần đây AI nổi lên mạnh mẽ xâm nhập vào rất nhiều lĩnh vực trong cuộc sống như tự động dịch thuật, nhận dạng giọng nói, điều khiển tự động, v.v. Nó giờ được coi là xu hướng công nghệ thế giới và nhiều người cho rằng đó là cuộc cách mạng công nghiệp lần thứ 4.&lt;/p&gt;</description></item></channel></rss>