<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Nn on Hai&#39;s Blog</title><link>https://dominhhai.github.io/vi/tags/nn/</link><description>Recent content in Nn on Hai&#39;s Blog</description><generator>Hugo -- gohugo.io</generator><language>vi</language><lastBuildDate>Sun, 08 Jul 2018 10:20:14 +0900</lastBuildDate><atom:link href="https://dominhhai.github.io/vi/tags/nn/index.xml" rel="self" type="application/rss+xml"/><item><title>[Talk] Slide về RNNs, LSTM, GRU</title><link>https://dominhhai.github.io/vi/2018/07/talk-rnn/</link><pubDate>Sun, 08 Jul 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/07/talk-rnn/</guid><description>&lt;p&gt;Dưới đấy là slide giới thiệu về RNNs, LSTM, GRU tại &lt;a href=&#34;https://www.facebook.com/events/1772695682776739/&#34;&gt;Tokyo ML Event&lt;/a&gt; hôm chủ nhật 08/07/2018 vừa qua. Tiện đây, blog mình có thêm mục &lt;strong&gt;&lt;a href=&#34;https://dominhhai.github.io/vi/talk/&#34;&gt;Chém gió&lt;/a&gt;&lt;/strong&gt; lưu trữ lại các slide trình bày của mình tại các hội nhóm.&lt;/p&gt;</description></item><item><title>[NN] Mạng quá khớp - Overfitting</title><link>https://dominhhai.github.io/vi/2018/05/nn-overfitting/</link><pubDate>Mon, 28 May 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/05/nn-overfitting/</guid><description>&lt;p&gt;Cũng như các bài toán ML khác, mạng NN hoàn toàn có thể bị quá khớp nếu kích cỡ lớn quá mức cần thiết. Nên khi cài đặt mạng NN, người ta thường cài thêm các phương pháp như &lt;em&gt;chính quy hoá&lt;/em&gt;, &lt;em&gt;bỏ nút mạng&lt;/em&gt;&amp;hellip; nhằm giảm được vấn đề này.&lt;/p&gt;</description></item><item><title>[NN] Về lan truyền ngược - Backpropagation</title><link>https://dominhhai.github.io/vi/2018/04/nn-bp/</link><pubDate>Fri, 27 Apr 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/04/nn-bp/</guid><description>&lt;p&gt;Bài viết này được dịch lại từ &lt;a href=&#34;https://colah.github.io/posts/2015-08-Backprop/&#34;&gt;bài của anh Christopher Olah&lt;/a&gt; bởi anh ấy trình bày rất chi tiết và cực dễ hiểu nên mình không viết lại làm gì cho phí công nữa.
Nội dung của bài viết này không phải về chi tiết giải thuật lan truyền ngược mà viết về nguyên lý cơ bản của giải thuật này. Nếu bạn cần xem chi tiết giải thuật được thực hiện ra sao thì có thể đọc &lt;a href=&#34;https://dominhhai.github.io/vi/2018/04/nn-intro/#5-lan-truyền-ngược-và-đạo-hàm&#34;&gt;bài viết trước của tôi&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>[NN] Cài đặt mạng NN</title><link>https://dominhhai.github.io/vi/2018/04/nn-implement/</link><pubDate>Thu, 26 Apr 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/04/nn-implement/</guid><description>&lt;p&gt;Bài viết này sẽ tập trung vào việc cài đặt mạng NN để nhận dạng số và đưa ra một số mẹo để thu được kết quả tốt khi làm việc với mạng NN. Nếu bạn chưa có cái nhìn tổng quan về mặt lý thuyết của mạng NN thì tôi nghĩ rằng bạn nên đọc &lt;a href=&#34;https://dominhhai.github.io/vi/2018/04/nn-intro/&#34;&gt;bài viết trước&lt;/a&gt; của tôi để có thể dễ dàng hiểu bài này hơn.&lt;/p&gt;</description></item><item><title>[NN] Mạng nơ-ron nhân tạo - Neural Networks</title><link>https://dominhhai.github.io/vi/2018/04/nn-intro/</link><pubDate>Mon, 23 Apr 2018 10:20:14 +0900</pubDate><guid>https://dominhhai.github.io/vi/2018/04/nn-intro/</guid><description>&lt;p&gt;Mạng nơ-ron nhân tạo (&lt;em&gt;Neural Network&lt;/em&gt; - &lt;strong&gt;NN&lt;/strong&gt;) là một mô hình lập trình rất đẹp lấy cảm hứng từ mạng nơ-ron thần kinh. Kết hợp với các kĩ thuật học sâu (&lt;em&gt;Deep Learning&lt;/em&gt; - &lt;strong&gt;DL&lt;/strong&gt;), NN đang trở thành một công cụ rất mạnh mẽ mang lại hiệu quả tốt nhất cho nhiều bài toán khó như nhận dạng ảnh, giọng nói hay xử lý ngôn ngữ tự nhiên.&lt;/p&gt;</description></item></channel></rss>