<!doctype html><html lang=vi><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=generator content="Hugo 0.41 with theme Tranquilpeak 0.4.1-BETA"><title>[RNN] RNN là gì?</title><meta name=author content="Do Minh Hai"><meta name=keywords content="Mạng RNN,Học Sâu,Deep Learning,dominhhai,programming,computer science,machine learning,deep learning"><link rel=icon href=https://dominhhai.github.io/favicon/golden-buddha-512-79567.png><link rel=canonical href=https://dominhhai.github.io/vi/2017/10/what-is-rnn/><meta name=description content="Bài giới thiệu RNN này được dịch lại từ trang blog WILDML.


Mạng nơ-ron hồi quy (RNN - Recurrent Neural Network) là một thuật toán được chú ý rất nhiều trong thời gian gần đây bởi các kết quả tốt thu được trong lĩnh vực xử lý ngôn ngữ tự nhiên."><link rel=publisher href=https://plus.google.com/115106277658014197977><meta property=fb:app_id content=333198270561466><meta property=og:locale content=vi_VN><meta property=og:type content=article><meta property=article:author content=dominhai><meta property=og:title content="[RNN] RNN là gì?"><meta property=og:url content=https://dominhhai.github.io/vi/2017/10/what-is-rnn/><meta property=og:description content="Bài giới thiệu RNN này được dịch lại từ trang blog WILDML.


Mạng nơ-ron hồi quy (RNN - Recurrent Neural Network) là một thuật toán được chú ý rất nhiều trong thời gian gần đây bởi các kết quả tốt thu được trong lĩnh vực xử lý ngôn ngữ tự nhiên."><meta property=og:site_name content="Hai's Blog"><meta property=og:image content=https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png><meta property=og:image content="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=640"><meta name=twitter:creator content=@minhhai3b><meta name=twitter:card content=summary><meta name=twitter:title content="[RNN] RNN là gì?"><meta name=twitter:url content=https://dominhhai.github.io/vi/2017/10/what-is-rnn/><meta name=twitter:description content="Bài giới thiệu RNN này được dịch lại từ trang blog WILDML.


Mạng nơ-ron hồi quy (RNN - Recurrent Neural Network) là một thuật toán được chú ý rất nhiều trong thời gian gần đây bởi các kết quả tốt thu được trong lĩnh vực xử lý ngôn ngữ tự nhiên."><meta name=twitter:image content="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=640"><meta name=twitter:image content=https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin=anonymous><link rel=stylesheet href=https://dominhhai.github.io/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css><link rel=stylesheet crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css integrity=sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei><link rel=stylesheet href=https://dominhhai.github.io/css/main.css><script async src="https://www.googletagmanager.com/gtag/js?id=UA-105333519-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)};gtag('js',new Date());gtag('config','UA-105333519-1');</script></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=https://dominhhai.github.io/vi/>Hai&#39;s Blog</a></div><a class=header-right-picture href=https://dominhhai.github.io/#about><img class=header-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=90" alt="Ảnh đại diện"></a></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=https://dominhhai.github.io/#about><img class=sidebar-profile-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=110" alt="Ảnh đại diện"></a><h4 class=sidebar-profile-name>Do Minh Hai</h4><h5 class=sidebar-profile-bio>Just a developer<br>Enjoy life as a journey</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Trang chủ</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/categories/><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Danh mục</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/tags/><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Thẻ thông tin</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/archives/><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Lưu trữ</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/talk/><i class="sidebar-button-icon fa fa-lg fa-child"></i><span class=sidebar-button-desc>Chém gió</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/page/why/><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>Hỏi ngu</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/dominhhai target=_blank rel=noopener><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://twitter.com/minhhai3b target=_blank rel=noopener><i class="sidebar-button-icon fa fa-lg fa-twitter"></i><span class=sidebar-button-desc>Twitter</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div id=main data-behavior=5 class=hasCoverMetaIn><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class="post-header main-content-wrap text-center"><h1 class=post-title itemprop=headline>[RNN] RNN là gì?</h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-10-19T00:00:00Z>19 tháng 10, 2017</time>
<span>mục</span>
<a class=category-link href=https://dominhhai.github.io/vi/categories/h%e1%bb%8dc-m%c3%a1y>Học Máy</a>,
<a class=category-link href=https://dominhhai.github.io/vi/categories/h%e1%bb%8dc-s%c3%a2u>Học Sâu</a>,
<a class=category-link href=https://dominhhai.github.io/vi/categories/rnn>RNN</a></div></div><div class="post-content markdown" itemprop=articleBody><div class=main-content-wrap><blockquote><p>Bài giới thiệu RNN này được dịch lại từ trang <a href=http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/ target=_blank _ rel="noopener noreferrer">blog WILDML</a>.</p></blockquote><p>Mạng nơ-ron hồi quy (RNN - Recurrent Neural Network) là một thuật toán được chú ý rất nhiều trong thời gian gần đây bởi các kết quả tốt thu được trong lĩnh vực xử lý ngôn ngữ tự nhiên.</p><p>Tuy nhiên, ta vẫn thiếu các bài viết giải thích tường tận về cách hoạt động, cách xây dựng mạng RNN, nên trong chuỗi bài viết này tôi sẽ viết về các vấn đề đó.
Chuỗi bài viết được chia thành 4 phần sau:</p><ul><li>1. Giới thiệu RNN (bài viết này)</li><li>2. <a href=https://dominhhai.github.io/vi/2017/10/implement-rnn-with-python/>Cài đặt RNN với Python và Theano</a></li><li>3. <a href=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/>Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm</a></li><li>4. <a href=https://dominhhai.github.io/vi/2017/10/implement-gru-lstm/>Cài đặt GRU/LSTM</a></li></ul><h1 id=table-of-contents>Mục lục</h1><nav id=TableOfContents><ul><li><a href=#1-mô-hình-ngôn-ngữ>1. Mô hình ngôn ngữ</a></li><li><a href=#2-mạng-hồi-quy-rnn-là-gì>2. Mạng hồi quy RNN là gì?</a></li><li><a href=#3-khả-năng-của-rnn>3. Khả năng của RNN</a><ul><li><a href=#3-1-mô-hình-hóa-ngôn-ngữ-và-sinh-văn-bản>3.1. Mô hình hóa ngôn ngữ và sinh văn bản</a></li><li><a href=#3-2-dịch-máy>3.2. Dịch máy</a></li><li><a href=#3-3-nhận-dạng-giọng-nói>3.3. Nhận dạng giọng nói</a></li><li><a href=#3-4-mô-tả-hình-ảnh>3.4. Mô tả hình ảnh</a></li></ul></li><li><a href=#4-huấn-luyện-rnn>4. Huấn luyện RNN</a></li><li><a href=#5-rnn-mở-rộng>5. RNN mở rộng</a><ul><li><a href=#5-1-rnn-2-chiều>5.1. RNN 2 chiều</a></li><li><a href=#5-2-rnn-2-chiều-sâu>5.2. RNN (2 chiều) sâu</a></li><li><a href=#5-3-mạng-lstm>5.3. Mạng LSTM</a></li></ul></li><li><a href=#6-kết-luận>6. Kết luận</a></li></ul></nav><h1 id=1-mô-hình-ngôn-ngữ>1. Mô hình ngôn ngữ</h1><p>Ok, giờ tôi sẽ trình bày về mô hình ngôn ngữ dựa trên RNN.
Ứng dụng của mô hình ngôn ngữ gồm 2 dạng.
Một là đánh giá độ chính xác của một câu dựa theo mức độ tương tự của chúng trên thực tế.
Việc đánh giá này giúp ta ước lượng được độ chính xác của văn phạm lẫn ngữ nghĩa của một câu.
Những mô hình này thường được ứng dụng trong các hệ thống dịch máy (Machine Translation).
Hai là tự động sinh văn bản (tôi cho rằng ứng dụng này hấp dẫn hơn).
Ví dụ huấn luyện mô hình với các tác phẩm của Shakespeare có thể cho phép ta sinh ra
các câu từ tựa như cách Shakespeare viết.
Ngoài ra, nếu có thời gian, các bạn có thể tham khảo thêm <a href=https://karpathy.github.io/2015/05/21/rnn-effectiveness/ target=_blank _ rel="noopener noreferrer">bài viết thú vị này</a> (tiếng Anh) của Andrej Karpathy về khả năng của các mô hình ngôn ngữ mức độ từ vựng.</p><p>Bài viết này dành cho các bạn đã biết cơ bản về mạng nơ-rơn (Neural Network),
nếu bạn chưa biết về mạng nơ-ron thì hãy đọc bài viết
<a href=http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/ target=_blank _ rel="noopener noreferrer">Cài đặt mạng nơ-ron cơ bản</a>.
Bài viết đó sẽ giúp bạn có cái nhìn cơ bản về ý tưởng và cách xây dựng một mạng nơ-ron cơ bản - mạng nơ-ron phi hồi quy.</p><h1 id=2-mạng-hồi-quy-rnn-là-gì>2. Mạng hồi quy RNN là gì?</h1><p>Ý tưởng chính của RNN (Recurrent Neural Network) là sử dụng chuỗi các thông tin.
Trong các mạng nơ-ron truyền thống tất cả các đầu vào và cả đầu ra là độc lập với nhau.
Tức là chúng không liên kết thành chuỗi với nhau. Nhưng các mô hình này không phù hợp trong rất nhiều bài toán.
Ví dụ, nếu muốn đoán từ tiếp theo có thể xuất hiện trong một câu thì ta cũng cần biết các từ trước đó xuất hiện lần lượt thế nào chứ nhỉ?
RNN được gọi là hồi quy (Recurrent) bởi lẽ chúng thực hiện cùng một tác vụ cho tất cả các phần tử của một chuỗi với đầu ra phụ thuộc vào cả các phép tính trước đó.
Nói cách khác, RNN có khả năng nhớ các thông tin được tính toán trước đó.
Trên lý thuyết, RNN có thể sử dụng được thông tin của một văn bản rất dài,
tuy nhiên thực tế thì nó chỉ có thể nhớ được một vài bước trước đó (ta cùng bàn cụ thể vấn đề này sau) mà thôi.
Về cơ bản một mạng RNN có dạng như sau:</p><div class="figure center"><a class=fancybox href=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg title="A recurrent neural network and the unfolding in time of the computation involved in its forward computation. Source: Nature" data-fancybox-group><img class=fig-img src=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg alt="A recurrent neural network and the unfolding in time of the computation involved in its forward computation. Source: Nature"></a>
<span class=caption>A recurrent neural network and the unfolding in time of the computation involved in its forward computation. Source: Nature</span></div><p>Mô hình trên mô tả phép triển khai nội dung của một RNN.
Triển khai ở đây có thể hiểu đơn giản là ta vẽ ra một mạng nơ-ron chuỗi tuần tự.
Ví dụ ta có một câu gồm 5 chữ &ldquo;<em>Đẹp trai lắm gái theo</em>&rdquo;,
thì mạng nơ-ron được triển khai sẽ gồm 5 tầng nơ-ron tương ứng với mỗi chữ một tầng.
Lúc đó việc tính toán bên trong RNN được thực hiện như sau:</p><ul><li>$ \color{blue}x_t $ là đầu vào tại bước $ \color{blue}t $.
Ví dụ, $ \color{deeppink}x_1 $ là một vec-tơ one-hot tương ứng với từ thứ 2 của câu (<em>trai</em>).</li><li><p>$ \color{blue}s_t $ là trạng thái ẩn tại bước $ \color{blue}t $.
Nó chính là <strong><em>bộ nhớ</em></strong> của mạng.
$ \color{blue}s_t $ được tính toán dựa trên cả các trạng thái ẩn phía trước và đầu vào tại bước đó:
$ \color{blue}s_t = f(U x_t + W s_{t-1} ) $.
Hàm $ \color{blue}f $ thường là một hàm phi tuyến tính như
<a href=https://vi.wikipedia.org/wiki/H%C3%A0m_hypebolic target=_blank _ rel="noopener noreferrer">tang hyperbolic (tanh)</a>
hay <a href=https://en.wikipedia.org/wiki/Rectifier_(neural_networks) target=_blank _ rel="noopener noreferrer">ReLu</a>.
Để làm phép toán cho phần tử ẩn đầu tiên ta cần khởi tạo thêm $ \color{deeppink}s_{-1} $,
thường giá trị khởi tạo được gắn bằng <code>0</code>.</p></li><li><p>$ \color{blue}o_t $ là đầu ra tại bước $ \color{blue}t $.
Ví dụ, ta muốn dự đoán từ tiếp theo có thể xuất hiện trong câu thì
$ \color{blue}o_t $ chính là một vec-tơ xác xuất các từ trong danh sách từ vựng của ta:
$ \color{blue}o_t = \mathrm{softmax}(V s_t) $</p></li></ul><h1 id=3-khả-năng-của-rnn>3. Khả năng của RNN</h1><p>Trong lĩnh vực xử lý ngôn ngữ tự nhiên (NLP - Natural Language Processing),
đã ghi nhận được nhiều thành công của RNN cho nhiều vấn đề khác nhau.
Tại thời điểm này, tôi muốn đề cập tới một mô hình phổ biến nhất được sử dụng của RNN là
<a href=https://en.wikipedia.org/wiki/Long_short-term_memory target=_blank _ rel="noopener noreferrer">LSTM</a>.
LSTM (Long Short-Term Memory) thể hiện được sự ưu việt ở điểm có thể nhớ được nhiều bước hơn mô hình RNN truyền thống.
Nhưng bạn không cần phải quá lo lắng vì LSTM về cơ bản giống với cấu trúc của RNN truyền thống,
chúng chỉ khác nhau ở cách tính toán của các nút ẩn.
Chúng ta sẽ cùng xem chi tiết hơn về LSTM trong <a href=https://dominhhai.github.io/vi/2017/10/what-is-rnn/>bài viết tiếp theo</a>.
Còn giờ, ta cùng nhau xem một vài ứng dụng của RNN trong xử lý ngôn ngữ tự nhiên dưới đây.</p><h2 id=3-1-mô-hình-hóa-ngôn-ngữ-và-sinh-văn-bản>3.1. Mô hình hóa ngôn ngữ và sinh văn bản</h2><p>Mô hình ngôn ngữ cho phép ta dự đoán được xác xuất của một từ nào đó xuất hiện sau một chuỗi các từ đi liền trước nó.
Do có khả năng ước lượng được độ tương tự của các câu nên nó còn được ứng dụng cho việc dịch máy.
Một điểm lý thú của việc có thể dự đoán được từ tiếp theo là ta có thể xây dựng được
một mô hình tự sinh từ cho phép máy tính có thể tự tạo ra các văn bản mới từ tập mẫu và xác xuất đầu ra của mỗi từ.
Vậy nên, tùy thuộc vào mô hình ngôn ngữ mà ta có thể tạo ra được nhiều
<a href=http://karpathy.github.io/2015/05/21/rnn-effectiveness/ target=_blank _ rel="noopener noreferrer">văn bản khác nhau</a>
khá là thú vị phải không.
Trong mô hình ngôn ngữ, đầu vào thường là một chuỗi các từ (được mô tả bằng vec-tơ one-hot)
và đầu ra là một chuỗi các từ dự đoán được.
Khi huấn luyện mạng, ta sẽ gán $ \color{blue}o_t = x_{t+1} $ vì ta muốn
đầu ra tại bước $ \color{blue}t $ chính là từ tiếp theo của câu.</p><p>Dưới đây là một vài nghiên cứu về mô hình hoá ngôn ngữ và sinh văn bản:</p><ul><li><a href=http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf target=_blank _ rel="noopener noreferrer">Recurrent neural network based language model</a></li><li><a href=http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf target=_blank _ rel="noopener noreferrer">Extensions of Recurrent neural network based language model</a></li><li><a href=http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf target=_blank _ rel="noopener noreferrer">Generating Text with Recurrent Neural Networks</a></li></ul><h2 id=3-2-dịch-máy>3.2. Dịch máy</h2><p>Dịch máy (Machine Translation) tương tự như mô hình hóa ngôn ngữ ở điểm là
đầu vào là một chuỗi các từ trong ngôn ngữ nguồn (ngôn ngữ cần dịch - ví dụ là tiếng Việt).
Còn đầu ra sẽ là một chuỗi các từ trong ngôn ngữ đích (ngôn ngữ dịch - ví dụ là tiếng Anh).
Điểm khác nhau ở đây là đầu ra của ta chỉ xử lý sau khi đã xem xét toàn bộ chuỗi đầu vào.
Vì từ dịch đầu tiên của câu dịch cần phải có đầy đủ thông tin từ đầu vào cần dịch mới có thể suy luận được.</p><div class="figure center"><a class=fancybox href=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-17-at-10.39.06-AM-1024x557.png title="RNN for Machine Translation. Image Source: http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf" data-fancybox-group><img class=fig-img src=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-17-at-10.39.06-AM-1024x557.png alt="RNN for Machine Translation. Image Source: http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf"></a>
<span class=caption>RNN for Machine Translation. Image Source: http://cs224d.stanford.edu/lectures/CS224d-Lecture8.pdf</span></div><p>Dưới đây là một vài nghiên cứu về dịch máy:</p><ul><li><a href=http://www.aclweb.org/anthology/P14-1140.pdf target=_blank _ rel="noopener noreferrer">A Recursive Recurrent Neural Network for Statistical Machine Translation</a></li><li><a href=http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf target=_blank _ rel="noopener noreferrer">Sequence to Sequence Learning with Neural Networks</a></li><li><a href=http://research.microsoft.com/en-us/um/people/gzweig/Pubs/EMNLP2013RNNMT.pdf target=_blank _ rel="noopener noreferrer">Joint Language and Translation Modeling with Recurrent Neural Networks</a></li></ul><h2 id=3-3-nhận-dạng-giọng-nói>3.3. Nhận dạng giọng nói</h2><p>Đưa vào một chuỗi các tín hiệu âm thanh, ta có thể dự đoán được chuỗi các đoạn ngữ âm đi kèm với xác xuất của chúng.</p><p>Dưới đây là một vài nghiên cứu về nhận dạng giọng nói:</p><ul><li><a href=http://www.jmlr.org/proceedings/papers/v32/graves14.pdf target=_blank _ rel="noopener noreferrer">Towards End-to-End Speech Recognition with Recurrent Neural Networks</a></li></ul><h2 id=3-4-mô-tả-hình-ảnh>3.4. Mô tả hình ảnh</h2><p>Cùng với <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network target=_blank _ rel="noopener noreferrer">ConvNet</a>,
RNN được sử dụng để tự động tạo mô tả cho các ảnh chưa được gán nhãn.
Sự kết hợp này đã đưa ra được các kết quả khá kinh ngạc.
Ví dụ như các ảnh dưới đây, các mô tả sinh ra có mức độ chính xác và độ tường tận khá cao.</p><div class="figure center"><a class=fancybox href=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-17-at-11.44.24-AM-1024x349.png title="Deep Visual-Semantic Alignments for Generating Image Descriptions. Source: http://cs.stanford.edu/people/karpathy/deepimagesent/" data-fancybox-group><img class=fig-img src=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-17-at-11.44.24-AM-1024x349.png alt="Deep Visual-Semantic Alignments for Generating Image Descriptions. Source: http://cs.stanford.edu/people/karpathy/deepimagesent/"></a>
<span class=caption>Deep Visual-Semantic Alignments for Generating Image Descriptions. Source: http://cs.stanford.edu/people/karpathy/deepimagesent/</span></div><h1 id=4-huấn-luyện-rnn>4. Huấn luyện RNN</h1><p>Huấn luyện mạng RNN cũng tương tự như các mạng nơ-ron truyền thống,
tuy nhiên giải thuật lan truyền ngược (backpropagation) phải thay đổi một chút.
Đạo hàm tại mỗi đầu ra phụ thuộc không chỉ vào các tính toán tại bước đó,
mà còn phụ thuộc vào các bước trước đó nữa,
vì các tham số trong mạng RNN được sử dụng chung cho tất cả các bước trong mạng.
Ví dụ, để tính đạo hàm tại $ \color{deeppink}t = 4 $ ta phải lan truyền ngược cả 3 bước phía trước
rồi cộng tổng đạo hàm của chúng lại với nhau.
Việc tính đạo hàm kiểu này được gọi là lan truyền ngược liên hồi
(<a href=https://en.wikipedia.org/wiki/Backpropagation_through_time target=_blank _ rel="noopener noreferrer">BPTT</a> - Backpropagation Through Time).
Nếu giờ bạn chưa thể hiểu được BPTT thế nào thì cũng đừng lo sợ
vì trong bài sau ta sẽ xem xét cụ thể nó là gì sau.
Còn giờ, chỉ cần nhớ rằng với các bước phụ thuộc càng xa thì việc học sẽ <a href=https://arxiv.org/pdf/1211.5063v2.pdf target=_blank _ rel="noopener noreferrer">càng khó khăn hơn</a>
vì sẽ xuất hiện vấn đề hao hụt/bùng nổ (vanishing/exploding) của đạo hàm.
Có một vài phương pháp được đề xuất để giải quyết vấn đề này
và các kiểu mạng RNN hiện nay đã được thiết kế để triệt tiêu bớt chúng như LSTM chẳng hạn.</p><h1 id=5-rnn-mở-rộng>5. RNN mở rộng</h1><p>Trong nhiều năm, các nhà nghiên cứu đã phát triển nhiều kiểu RNN tinh vi
để xử lý các nhược điểm của mô hình RNN truyền thống.
Chúng ta sẽ xem chi tiết một vài mô hình đó ở các bài viết sau,
còn ở bài này, tôi chỉ giới thiệu ngắn ngọn 2 mô hình dưới đây.</p><h2 id=5-1-rnn-2-chiều>5.1. RNN 2 chiều</h2><p>Ở mô hình RNN 2 chiều (Bidirectional RNN), đầu ra tại bước $ \color{blue}t $
không những phụ thuộc vào các phần tử phía trước mà còn phụ thuộc cả vào các phần tử phía sau.
Ví dụ, để dự đoán từ còn thiếu trong câu, thì việc xem xét cả phần trước và phần sau của câu là cần thiết.
Vì vậy, ta có thể coi mô hình là việc chồng 2 mạng RNN ngược hướng nhau lên nhau.
Lúc này đầu ra được tính toán dựa vào cả 2 trạng thái ẩn của 2 mạng RNN ngược hướng này.</p><div class="figure center"><a class=fancybox href=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/bidirectional-rnn-300x196.png title="Bidirectional RNNs" data-fancybox-group><img class=fig-img src=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/bidirectional-rnn-300x196.png alt="Bidirectional RNNs"></a>
<span class=caption>Bidirectional RNNs</span></div><h2 id=5-2-rnn-2-chiều-sâu>5.2. RNN (2 chiều) sâu</h2><p>RNN sâu (Deep (Bidirectional) RNN) cũng tương tự như RNN 2 chiều,
nhưng khác nhau ở chỗ chúng chứa nhiều tầng ẩn ở mỗi bước.
Trong thực tế, chúng giúp cho việc học ở mức độ cao hơn,
tuy nhiên ta cũng cần phải có nhiều dữ liệu huấn luyện hơn.</p><div class="figure center"><a class=fancybox href=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-16-at-2.21.51-PM-272x300.png title="Deep (Bidirectional) RNNs" data-fancybox-group><img class=fig-img src=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/Screen-Shot-2015-09-16-at-2.21.51-PM-272x300.png alt="Deep (Bidirectional) RNNs"></a>
<span class=caption>Deep (Bidirectional) RNNs</span></div><h2 id=5-3-mạng-lstm>5.3. Mạng LSTM</h2><p>Gần đây, mạng LSTM mà ta có đề cập một chút phía trên được chú ý và sử dụng khá phổ biến.
Về cơ bản mô hình của LSTM không khác mô hình truyền thống của RNN,
nhưng chúng sử dụng hàm tính toán khác ở các trạng thái ẩn.
Bộ nhớ của LSTM được gọi là tế bào (Cell) và bạn có thể tưởng tượng rằng chúng là các hộp đen
nhận đầu vào là trạng thái phía trước $ \color{blue}h_{t-1} $ và đầu vào hiện tại $ \color{blue}x_t $.
Bên trong hộp đen này sẽ tự quyết định cái gì cần phải nhớ và cái gì sẽ xoá đi.
Sau đó, chúng sẽ kết hợp với trạng thái phía trước, nhớ hiện tại và đầu vào hiện tại.
Vì vậy mà ta ta có thể truy xuất được quan hệ của các từ phụ thuộc xa nhau rất hiệu quả.
Có thể khi mới làm quen với LSTM thì chúng hơi khó hiểu đôi chút, nhưng nếu bạn có hứng thú thì hãy xem
<a href=https://colah.github.io/posts/2015-08-Understanding-LSTMs/ target=_blank _ rel="noopener noreferrer">bài viết xuất sắc này</a>
(<a href=https://dominhhai.github.io/vi/2017/10/what-is-lstm/ target=_blank _ rel="noopener noreferrer">bản dịch tại đây</a>).</p><h1 id=6-kết-luận>6. Kết luận</h1><p>Okey, được rồi, tôi hi vọng là bạn đã hiểu cơ bản về RNN và khả năng của chúng.
Trong bài viết tiếp theo, chúng ta sẽ cài đặt phiên bản đầu tiên của mô hình ngôn ngữ RNN sử dụng <code>Python</code>
và <a href=http://www.deeplearning.net/software/theano/ target=_blank _ rel="noopener noreferrer">Theano</a>.
Giờ nếu bạn có thắc mắc gì thì có thể để lại câu hỏi ở phía dưới nhé!</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small">THẺ ĐÁNH DẤU</span><br><a class="tag tag--primary tag--small" href=https://dominhhai.github.io/vi/tags/rnn/>RNN</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/what-is-lstm/ data-tooltip="[RNN] LSTM là gì?"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml">Tiếp</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/prob-4-ml/ data-tooltip="[Xác Suất] Đằng sau giải thuật phân loại"><span class="hide-xs hide-sm text-small icon-mr">Trước</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=https://dominhhai.github.io/vi/2017/10/what-is-rnn/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dominhhai.github.io/vi/2017/10/what-is-rnn/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=https://dominhhai.github.io/vi/2017/10/what-is-rnn/"><i class="fa fa-google-plus"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#fb-cmt-thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#table-of-contents><i class="fa fa-list"></i></a></li></ul></div><div id=fb-root></div><script>(function(d,s,id){if(window.location.hostname=='localhost')return;var js,fjs=d.getElementsByTagName(s)[0];if(d.getElementById(id))return;js=d.createElement(s);js.id=id;js.async=true;js.src='https://connect.facebook.net/vi_VN/sdk.js#xfbml=1&version=v3.1&appId=333198270561466&autoLogAppEvents=1';fjs.parentNode.insertBefore(js,fjs);}(document,'script','facebook-jssdk'));</script><div id=fb-cmt-thread class=fb-comments data-href=https://dominhhai.github.io/vi/2017/10/what-is-rnn/ data-width=100%></div></div></article><footer id=footer class=main-content-wrap><div id=helpinfo><div id=author><label id=home>Hai's Blog</label><div class=language><label for=language>Other Languages:</label>
<select id=language>
<option title="Tiếng Việt" value=vi selected>Tiếng Việt (vi)</option>
<option title=English value=en-us>English (en-us)</option>
<option title=日本語 value=ja>日本語 (ja)</option></select></div></div><div id=topic><label>Chủ đề</label><ul><li><a href=https://dominhhai.github.io/vi/categories/l%E1%BA%ADp-tr%C3%ACnh/>Lập Trình</a></li><li><a href=https://dominhhai.github.io/vi/categories/h%E1%BB%8Dc-m%C3%A1y/>Học Máy</a></li><li><a href=https://dominhhai.github.io/vi/categories/to%C3%A1n/>Toán</a></li><li><a href=https://dominhhai.github.io/vi/categories/x%C3%A1c-su%E1%BA%A5t/>Xác Suất</a></li><li><a href=https://dominhhai.github.io/vi/categories/s%C3%A1ch/>Sách</a></li></ul></div><div id=contact><label>Liên hệ</label><ul><li><a href=https://github.com/dominhhai/dominhhai.github.io/issues/new target=_blank><i class="fa fa-lg fa-inbox"></i>Gửi tin nhắn</a></li><li id=follow><a href=https://github.com/dominhhai target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i></a><a href=https://twitter.com/minhhai3b target=_blank><i class="sidebar-button-icon fa fa-lg fa-twitter"></i></a></li></ul></div></div><div id=contentinfo><span class=copyrights>&copy; 2018 <a href=https://github.com/dominhhai>Do Minh Hai</a>. All Rights Reserved</span></div></footer></div><div id=bottom-bar class=post-bottom-bar data-behavior=5><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/what-is-lstm/ data-tooltip="[RNN] LSTM là gì?"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml">Tiếp</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/prob-4-ml/ data-tooltip="[Xác Suất] Đằng sau giải thuật phân loại"><span class="hide-xs hide-sm text-small icon-mr">Trước</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=https://dominhhai.github.io/vi/2017/10/what-is-rnn/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dominhhai.github.io/vi/2017/10/what-is-rnn/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=https://dominhhai.github.io/vi/2017/10/what-is-rnn/"><i class="fa fa-google-plus"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#fb-cmt-thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#table-of-contents><i class="fa fa-list"></i></a></li></ul></div></div><div id=share-options-bar class=share-options-bar data-behavior=5><i id=btn-close-shareoptions class="fa fa-close"></i><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2017%2F10%2Fwhat-is-rnn%2F"><i class="fa fa-facebook-official"></i><span>Chia sẻ với Facebook</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2017%2F10%2Fwhat-is-rnn%2F"><i class="fa fa-twitter"></i><span>Chia sẻ với Twitter</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://plus.google.com/share?url=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2017%2F10%2Fwhat-is-rnn%2F"><i class="fa fa-google-plus"></i><span>Chia sẻ với Google&#43;</span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=110" alt="Ảnh đại diện"><h4 id=about-card-name>Do Minh Hai</h4><div id=about-card-bio>Just a developer<br>Enjoy life as a journey</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Freelancer</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Japan</div></div></div><div id=cover style=background-image:url(https://dominhhai.github.io/images/cover-v1.2.0.jpg)></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin=anonymous></script><script src=https://dominhhai.github.io/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js></script><script crossorigin=anonymous integrity=sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js></script><script crossorigin=anonymous integrity=sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/contrib/auto-render.min.js></script><script src=https://dominhhai.github.io/js/main.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight > code, pre > code').each(function(i,block){if(!$(this).hasClass('codeblock')){$(this).addClass('codeblock');}
hljs.highlightBlock(block);});});</script><script>var disqus_config=function(){this.page.url='https:\/\/dominhhai.github.io\/vi\/2017\/10\/what-is-rnn\/';this.page.identifier='\/vi\/2017\/10\/what-is-rnn\/'};(function(){if(window.location.hostname=="localhost"){return;}
var d=document,s=d.createElement('script');var disqus_shortname='tranquilpeak';s.src='//'+disqus_shortname+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><script>if(typeof fnMain==='function'){fnMain();}</script></body></html>