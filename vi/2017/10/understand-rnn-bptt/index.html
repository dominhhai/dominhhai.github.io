<!doctype html><html lang=vi><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.54.0 with theme Tranquilpeak 0.4.1-BETA"><title>[RNN] Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm</title><meta name=author content="Do Minh Hai"><meta name=keywords content="Mạng RNN,Học Sâu,Deep Learning,dominhhai,programming,computer science,machine learning,deep learning"><link rel=icon href=https://dominhhai.github.io/favicon/golden-buddha-512-79567.png><link rel=canonical href=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/><meta name=description content="Bài giới thiệu RNN thứ 3 này được dịch lại từ trang blog WILDML.


Trong phần này tôi sẽ giới thiệu tổng quan về BPTT (Backpropagation Through Time) và giải thích sự khác biệt của nó so với các giải thuật lan truyền ngược truyền thống.
Sau đó ta sẽ cùng tìm hiểu vấn đề mất mát đạo hàm (vanishing gradient problem), nó dẫn ta tới việc phát triển của LSTM và GRU - 2 mô hình phổ biến và mạnh mẽ nhất hiện nay trong các bài toán NLP (và cả các lĩnh vực khác)."><link rel=publisher href=https://plus.google.com/115106277658014197977><meta property=fb:app_id content=333198270561466><meta property=og:locale content=vi_VN><meta property=og:type content=article><meta property=article:author content=dominhai><meta property=og:title content="[RNN] Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm"><meta property=og:url content=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/><meta property=og:description content="Bài giới thiệu RNN thứ 3 này được dịch lại từ trang blog WILDML.


Trong phần này tôi sẽ giới thiệu tổng quan về BPTT (Backpropagation Through Time) và giải thích sự khác biệt của nó so với các giải thuật lan truyền ngược truyền thống.
Sau đó ta sẽ cùng tìm hiểu vấn đề mất mát đạo hàm (vanishing gradient problem), nó dẫn ta tới việc phát triển của LSTM và GRU - 2 mô hình phổ biến và mạnh mẽ nhất hiện nay trong các bài toán NLP (và cả các lĩnh vực khác)."><meta property=og:site_name content="Hai's Blog"><meta property=og:image content=https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png><meta property=og:image content="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=640"><meta name=twitter:creator content=@minhhai3b><meta name=twitter:card content=summary><meta name=twitter:title content="[RNN] Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm"><meta name=twitter:url content=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/><meta name=twitter:description content="Bài giới thiệu RNN thứ 3 này được dịch lại từ trang blog WILDML.


Trong phần này tôi sẽ giới thiệu tổng quan về BPTT (Backpropagation Through Time) và giải thích sự khác biệt của nó so với các giải thuật lan truyền ngược truyền thống.
Sau đó ta sẽ cùng tìm hiểu vấn đề mất mát đạo hàm (vanishing gradient problem), nó dẫn ta tới việc phát triển của LSTM và GRU - 2 mô hình phổ biến và mạnh mẽ nhất hiện nay trong các bài toán NLP (và cả các lĩnh vực khác)."><meta name=twitter:image content="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=640"><meta name=twitter:image content=https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin=anonymous><link rel=stylesheet href=https://dominhhai.github.io/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css><link rel=stylesheet crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css integrity=sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei><link rel=stylesheet href=https://dominhhai.github.io/css/main.css><script async src="https://www.googletagmanager.com/gtag/js?id=UA-105333519-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)};gtag('js',new Date());gtag('config','UA-105333519-1');</script></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=https://dominhhai.github.io/vi/>Hai&#39;s Blog</a></div><a class=header-right-picture href=https://dominhhai.github.io/#about><img class=header-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=90" alt="Ảnh đại diện"></a></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=https://dominhhai.github.io/#about><img class=sidebar-profile-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=110" alt="Ảnh đại diện"></a><h4 class=sidebar-profile-name>Do Minh Hai</h4><h5 class=sidebar-profile-bio>Just a developer<br>Enjoy life as a journey</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Trang chủ</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/categories/><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Danh mục</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/tags/><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Thẻ thông tin</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/archives/><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Lưu trữ</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/talk/><i class="sidebar-button-icon fa fa-lg fa-child"></i><span class=sidebar-button-desc>Chém gió</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/page/why/><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>Hỏi ngu</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/dominhhai target=_blank rel=noopener><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://twitter.com/minhhai3b target=_blank rel=noopener><i class="sidebar-button-icon fa fa-lg fa-twitter"></i><span class=sidebar-button-desc>Twitter</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div id=main data-behavior=5 class=hasCoverMetaIn><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class="post-header main-content-wrap text-center"><h1 class=post-title itemprop=headline>[RNN] Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm</h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2017-10-22T00:00:00Z>22 tháng 10, 2017</time>
<span>mục</span>
<a class=category-link href=https://dominhhai.github.io/vi/categories/h%e1%bb%8dc-m%c3%a1y>Học Máy</a>,
<a class=category-link href=https://dominhhai.github.io/vi/categories/h%e1%bb%8dc-s%c3%a2u>Học Sâu</a>,
<a class=category-link href=https://dominhhai.github.io/vi/categories/rnn>RNN</a></div></div><div class="post-content markdown" itemprop=articleBody><div class=main-content-wrap><blockquote><p>Bài giới thiệu RNN thứ 3 này được dịch lại từ trang <a href=http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/ target=_blank _ rel="noopener noreferrer">blog WILDML</a>.</p></blockquote><p>Trong phần này tôi sẽ giới thiệu tổng quan về BPTT (Backpropagation Through Time) và giải thích sự khác biệt của nó so với các giải thuật lan truyền ngược truyền thống.
Sau đó ta sẽ cùng tìm hiểu vấn đề mất mát đạo hàm (vanishing gradient problem), nó dẫn ta tới việc phát triển của LSTM và GRU - 2 mô hình phổ biến và mạnh mẽ nhất hiện nay trong các bài toán NLP (và cả các lĩnh vực khác).</p><p>Vấn đề mất mát đạo hàm được khám phá bởi <a href=http://people.idsia.ch/~juergen/fundamentaldeeplearningproblem.html target=_blank _ rel="noopener noreferrer">Sepp Hochreiter năm 1991</a>
và đã cuốn hút được sự quan tâm cho lần nữa trong thời gian gần đây khi mà ứng dụng của các kiến trúc sâu ngày một nhiều hơn.</p><p>Đây là bài thứ 3 trong chuỗi bài giới thiệu về RNN:</p><ul><li>1. <a href=https://dominhhai.github.io/vi/2017/10/what-is-rnn/>Giới thiệu RNN</a></li><li>2. <a href=https://dominhhai.github.io/vi/2017/10/implement-rnn-with-python/>Cài đặt RNN với Python và Theano</a></li><li>3. Tìm hiểu về giải thuật BPTT và vấn đề mất mát đạo hàm (bài này)</li><li>4. <a href=https://dominhhai.github.io/vi/2017/10/implement-gru-lstm/>Cài đặt GRU/LSTM</a></li></ul><p>Để có thể hiểu được toàn bộ bài viết này, bạn cần có kiến thức về giải tích và cơ bản về giải thuật lan truyền ngược (backpropagation).
Nếu bạn chưa rõ nó thì có thể đọc tại các bài viết
<a href=http://cs231n.github.io/optimization-2/ target=_blank _ rel="noopener noreferrer">này</a>
và <a href=http://colah.github.io/posts/2015-08-Backprop/ target=_blank _ rel="noopener noreferrer">này</a>
và cả <a href=http://neuralnetworksanddeeplearning.com/chap2.html target=_blank _ rel="noopener noreferrer">đây</a> nữa (thứ tự khó dần nhé).</p><h1 id=table-of-contents>Mục lục</h1><nav id=TableOfContents><ul><li><a href=#1-lan-truyền-ngược-liên-hồi-bptt>1. Lan truyền ngược liên hồi - BPTT</a></li><li><a href=#2-vấn-đề-mất-mát-đạo-hàm>2. Vấn đề mất mát đạo hàm</a></li></ul></nav><h1 id=1-lan-truyền-ngược-liên-hồi-bptt>1. Lan truyền ngược liên hồi - BPTT</h1><p>Nhớ lại chút các công thức cơ bản của RNN. Lưu ý rằng các kí hiệu ở đây có thay đổi 1 chút từ $ o $ thành $ \hat{y} $.
Việc thay đổi này nhằm thống nhất với một vài tài liệu tôi sẽ tham chiếu tới.</p><p>$$
\begin{aligned}
s_t &amp;= \tanh(U x_t + W s_{t-1}) \cr
\hat{y_t} &amp;= \mathrm{softmax}(V s_t)
\end{aligned}
$$</p><p>Ta cũng định nghĩa hàm mất mát, hay hàm lỗi dạng cross entropy như sau:</p><p>$$
\begin{aligned}
E_t(y_t, \hat{y_t}) &amp;= -y_t \log{\hat{y_t}} \cr
E(y, \hat{y}) &amp;= \sum_t{E_t(y_t, \hat{y_t})} \cr
\ &amp;= -\sum_t{y_t \log{\hat{y_t}}}
\end{aligned}
$$</p><p>Ở đây, $ y_t $ là từ chính xác ở bước $ t $, còn $ \hat{y_t} $ là từ mà ta dự đoán.
Ta coi mỗi chuỗi đầy đủ (một câu) là một mẫu huấn luyện.
Vì vậy tổng số lỗi chính là tổng của tất cả các lỗi ở mỗi bước (mỗi từ).</p><div class="figure center"><a class=fancybox href=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/10/rnn-bptt1.png data-fancybox-group><img class=fig-img src=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/10/rnn-bptt1.png></a></div><p>Mục tiêu của ta là tính đạo hàm của lỗi với tham số $ U, V, W $ tương ứng và sau đó học các tham số này bằng cách sử dụng SGD.
Tương tự như việc cộng tổng các lỗi, ta cũng sẽ cộng tổng các đạo hàm tại mỗi bước cho mỗi mẫu huấn luyện:
$\displaystyle \frac{\partial{E}}{\partial{W}} = \sum_t{\frac{\partial{E_t}}{\partial{W}}} $.</p><p>Để tính đạo hàm, ta sử dụng <a href=https://en.wikipedia.org/wiki/Chain_rule target=_blank _ rel="noopener noreferrer">quy tắc chuỗi vi phân</a>.
Quy tắc này được áp dụng cho việc truyền ngược lỗi của <a href=http://colah.github.io/posts/2015-08-Backprop/ target=_blank _ rel="noopener noreferrer">giải thuật lan truyền ngược</a>.</p><p>$$
\begin{aligned}
\frac{\partial{E_3}}{\partial{V}} &amp;= \frac{\partial{E_3}}{\partial{\hat{y_3}}} \frac{\partial{\hat{y_3}}}{\partial{V}} \cr
\ &amp;= \frac{\partial{E_3}}{\partial{\hat{y_3}}} \frac{\partial{\hat{y_3}}}{\partial{z_3}} \frac{\partial{z_3}}{\partial{V}} \cr
\ &amp;= (\hat{y_3} - y_3) \otimes s_3
\end{aligned}
$$</p><p>Trong đó, $ z_3 = V s_3 $ và $ \otimes $ là <a href=https://en.wikipedia.org/wiki/Outer_product target=_blank _ rel="noopener noreferrer">phép nhân ngoài của 2 véc-tơ </a>.
Nếu bạn không hiểu phép khai triển trên thì cũng đừng lo lắng gì cả, tôi có bỏ qua 1 vài bước khi khai triển, nếu cần thiết bạn có thể tự tính đạo hàm xem khớp hay không.
Qua phép khai triển trên, tôi chỉ muốn nói 1 điều là $\displaystyle \frac{\partial{E_3}}{\partial{V}} $
chỉ phụ thuộc vào các giá trị ở bước hiện thời: $ \hat{y_3}, y_3, s_3 $ mà thôi.
Nhìn vào công thức đó, ta thấy rằng tính đạo hàm cho $ V $ chỉ đơn giản là phép nhân ma trận.</p><p>Nhưng với $ W $ và $ U $ thì phép tính của ta lại không đơn giản như vậy.</p><p>$$
\frac{\partial{E_3}}{\partial{W}} = \frac{\partial{E_3}}{\partial{\hat{y_3}}} \frac{\partial{\hat{y_3}}}{\partial{s_3}} \frac{\partial{s_3}}{\partial{W}}
$$</p><p>Với $ s_3 = \tanh{U x_t + W s_2} $ phụ thuộc vào $ s_2 $, còn $ s_2 $ lại phụ thuộc vào $ W $ và $ s_1 $,&hellip;
Vì vậy với W, ta không thể nào coi $ s_2 $ là hẳng số để tính toán như với $ V $ được.
Ta tiếp tục áp dụng quy tắc chuỗi xem sao:</p><p>$$
\frac{\partial{E_3}}{\partial{W}} = \frac{\partial{E_3}}{\partial{\hat{y_3}}} \frac{\partial{\hat{y_3}}}{\partial{s_3}} \frac{\partial{s_3}}{\partial{s_k}} \frac{\partial{s_k}}{\partial{W}}
$$</p><p>Như vậy, với W ta phải cộng tổng tất cả các đầu ra ở các bước trước để tính được đạo hàm.
Nói cách khác, ta phải truyền ngược đạo hàm từ $ t = 3 $ về tới $ t = 0 $.</p><div class="figure center"><a class=fancybox href=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/10/rnn-bptt-with-gradients.png data-fancybox-group><img class=fig-img src=https://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/10/rnn-bptt-with-gradients.png></a></div><p>Cách làm này cũng giống hệt như giải thuật truyền ngược chuẩn trong mạng nơ-ron truyền thống.
Điểm khác ở đây là ta cộng tổng các đạo hàm của W tại mỗi bước thời gian.
Trong mạng nơ-ron truyền thống, ta không chia sẻ các tham số cho các tầng mạng,
nên ta không cần phải cộng tổng đạo hàm lại với nhau.
Cũng tương tự như với lan truyền ngược truyền thống, ta có thể định nghĩa véc-tơ delta khi lan truyền ngược lại:
$\displaystyle \delta_x^{(3)} = \frac{\partial{E_3}}{\partial{z_2}} = \frac{\partial{E_3}}{\partial{s_3}} \frac{\partial{s_3}}{\partial{s_2}} \frac{\partial{s_2}}{\partial{z_2}} $ với $ z_2 = U x_2 + W s_1 $.
Các công thức tính toán tiếp theo hoàn toàn có thể dạng dụng tương tự.</p><p>Dưới đây là mà nguồn thực hiện BPTT:</p><figure class="highlight python language-python"><figcaption><span>bptt.py</span></figcaption><table><tbody><tr><td class=gutter><pre><span class=line>1</span><br><span class=line>2</span><br><span class=line>3</span><br><span class=line>4</span><br><span class=line>5</span><br><span class=line>6</span><br><span class=line>7</span><br><span class=line>8</span><br><span class=line>9</span><br><span class=line>10</span><br><span class=line>11</span><br><span class=line>12</span><br><span class=line>13</span><br><span class=line>14</span><br><span class=line>15</span><br><span class=line>16</span><br><span class=line>17</span><br><span class=line>18</span><br><span class=line>19</span><br><span class=line>20</span><br><span class=line>21</span><br><span class=line>22</span><br><span class=line>23</span><br><span class=line>24</span><br></pre></td><td class=code><pre class="code-highlight language-python"><code class=python>def bptt(self, x, y):
    T = len(y)
    # Perform forward propagation
    o, s = self.forward_propagation(x)
    # We accumulate the gradients in these variables
    dLdU = np.zeros(self.U.shape)
    dLdV = np.zeros(self.V.shape)
    dLdW = np.zeros(self.W.shape)
    delta_o = o
    delta_o[np.arange(len(y)), y] -= 1.
    # For each output backwards...
    for t in np.arange(T)[::-1]:
        dLdV &#43;= np.outer(delta_o[t], s[t].T)
        # Initial delta calculation: dL/dz
        delta_t = self.V.T.dot(delta_o[t]) * (1 - (s[t] ** 2))
        # Backpropagation through time (for at most self.bptt_truncate steps)
        for bptt_step in np.arange(max(0, t-self.bptt_truncate), t&#43;1)[::-1]:
            # print &#34;Backpropagation step t=%d bptt step=%d &#34; % (t, bptt_step)
            # Add to gradients at each previous step
            dLdW &#43;= np.outer(delta_t, s[bptt_step-1])              
            dLdU[:,x[bptt_step]] &#43;= delta_t
            # Update delta for next step dL/dz at t-1
            delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)
    return [dLdU, dLdV, dLdW]</code></pre></td></tr></tbody></table></figure><p>Nhìn vào đây, ta có thể biết được phần nào mạng RNN chuẩn khó để huấn luyện,
vì các chuỗi (câu) có thể khá dài đến tận 20 từ thậm chí nhiều hơn thế nên
ta cần phải truyền ngược lại thông qua rất nhiều tầng mạng.
Trong thực tế, người ta sẽ bỏ qua một vài bước truyền ở một số bước.</p><h1 id=2-vấn-đề-mất-mát-đạo-hàm>2. Vấn đề mất mát đạo hàm</h1><p>Với các câu dài RNN không thể liên kết được các từ ở cách xa nhau nên việc học các câu dài sẽ bị thất bại. Vậy nguyên nhân là gì, ta cùng bắt đầu tìm hiểu từ công thức tính đạo hàm:</p><p>$$
\frac{\partial{E_3}}{\partial{W}} = \sum_{k=0}^3{
\frac{\partial{E_3}}{\partial{\hat{y_3}}}
\frac{\partial{\hat{y_3}}}{\partial{s_3}}
\frac{\partial{s_3}}{\partial{s_k}}
\frac{\partial{s_k}}{\partial{W}}
}
$$</p><p>Ở đây, $\displaystyle \frac{s_3}{s_k} $ cũng tuân theo quy tắc chuỗi đạo hàm.
Ví dụ: $\displaystyle \frac{s_3}{s_1} = \frac{s_3}{s_2} \frac{s_2}{s_1} $.
Nếu bạn để ý thì sẽ thấy các thành phần ở công thức trên đều là véc-tơ vì phép lấy đạo hàm cho véc-tơ cũng là véc-tơ, nên kết quả thu được sẽ là một ma trận
(<a href=https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant target=_blank _ rel="noopener noreferrer">ma trận Jacobi</a>),
trong đó các phần tử tương ứng được tính theo phép toán <a href=https://en.wikipedia.org/wiki/Pointwise target=_blank _ rel="noopener noreferrer">pointwise</a> với đạo hàm tương ứng.
Ta có thể viết lại công thức trên như sau:</p><p>$$
\frac{\partial{E_3}}{\partial{W}} = \sum_{k=0}^3{
\frac{\partial{E_3}}{\partial{\hat{y_3}}}
\frac{\partial{\hat{y_3}}}{\partial{s_3}}
\Bigg(
\prod_{j=k+1}^3{
\frac{\partial{s_j}}{\partial{s_{j-1}}}
}
\Bigg)
\frac{\partial{s_k}}{\partial{W}}
}
$$</p><p>Tôi không chứng minh ở đây (bạn có thể xem ở <a href=http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf target=_blank _ rel="noopener noreferrer">đây</a>),
nhưng phép tính trên cho ta một norm bậc 2.
Bạn có thể coi nó là một giá trị tuyệt đối có biên trên là 1 của ma trận Jacobi ở trên.
Vì hàm kích hoạt ($ \tanh $ hay $ sigmoid $) của ta sẽ cho kết quả đầu ra nằm trong đoạn $ [-1, 1] $
nên đạo hàm của nó sẽ bị đóng trong khoảng $ [0, 1] $ (với $ sigmoid $ thì giá trị sẽ là $ [0, 0.25] $).</p><div class="figure center"><a class=fancybox href=https://nn.readthedocs.org/en/rtd/image/tanh.png title="tanh and derivative. Source: http://nn.readthedocs.org/en/rtd/transfer/" data-fancybox-group><img class=fig-img src=https://nn.readthedocs.org/en/rtd/image/tanh.png alt="tanh and derivative. Source: http://nn.readthedocs.org/en/rtd/transfer/"></a>
<span class=caption>tanh and derivative. Source: http://nn.readthedocs.org/en/rtd/transfer/</span></div><p>Nhìn vào hình trên, bạn có thể cả hàm $ \tanh $ lẫn $ sigmoid $ sẽ có đạo hàm bằng $ 0 $ tại 2 đầu.
Mà khi đạo hàm bằng 0 thì nút mạng tương ứng tại đó sẽ bị bão hòa. Lúc đó các nút phía trước cũng sẽ bị bão hoà theo.
Nên với các giá trị nhỏ trong ma trận, khi ta thực hiện phép nhân ma trận sẽ đạo hàm tương ứng sẽ bùng nổi rất nhanh, thậm chí nó sẽ bị triệt tiêu chỉ sau vài bước nhân.
Như vậy, các bước ở xa sẽ không còn tác dụng với nút hiện tại nữa, làm cho RNN không thể học được các phụ thuộc xa.
Vấn đề này không chỉ xảy ra với mạng RNN mà ngay cả mạng nơ-ron chuẩn khá sâu cũng có hiện tượng này.
Như bạn đã biết RNN cũng là một mạng chuẩn sâu, với số tầng mạng bằng với số từ đầu vào của một chuỗi, nên hiện tượng này có thể thấy ngay ở RNN.</p><p>Với cách nhìn như trên ta có thể suy luận thêm <em>vấn đề bùng nổ đạo hàm</em> của RNN nữa.
Tùy thuộc vào hàm kích hoạt và tham số của mạng, vấn đề bùng nổ đạo hàm có thể xảy ra khi các giá trị của ma trận là lớn.
Tuy nhiên, người ta thường nói về vấn đề <em>mất mát đạo hàm</em> nhiều hơn là <em>bùng nổ đạo hàm</em>,
vì 2 lý do sau. Thứ nhất, bùng nổ đạo hàm có thể theo dõi được
vì khi đạo hàm bị bùng nổ thì ta sẽ thu được kết quả là một giá trị phi số <em>NaN</em> làm cho chương trình của ta bị dừng hoạt động.
Lý do thứ 2 là bùng nổ đạo hàm có thể ngăn chặn được khi ta đặt một ngưỡng giá trị trên cho đạo hàm như trong <a href=http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf target=_blank _ rel="noopener noreferrer">bài viết này</a>.
Còn việc mất mát đạo hàm lại không theo dõi được mà cũng không biết làm sao để xử lý nó cho hợp lý.</p><p>May mắn là giờ đã có nhiều nghiên cứu chỉ ra các cách giải quyết vấn đề này.
Ví dụ như việc khởi tạo tham số $ W $ hợp lý sẽ giúp giảm được hiệu ứng mất mát đạo hàm.
Một phương pháp được ưu chuộng hơn là thay vì sử dụng $ \tanh $ và $ sigmoid $ cho hàm kích hoạt thì ta sử dụng $ ReLU $.
Đạo hàm ReLU sẽ là một số hoặc là 0 hoặc là 1, nên có ta có thể kiểm soát được vấn đề mất mát đạo hàm.
Một phương pháp phổ biến hơn cả là sử dụng kiến trúc nhớ dài-ngắn hạn (LSTM - Long Short-Term Memory) hoặc Gated Recurrent Unit (GRU).
LSTM được <a href=http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf target=_blank _ rel="noopener noreferrer">đề xuất vào năm 1997</a>
và có lẽ giờ nó là phương pháp phổ biến nhất trong lĩnh vực NLP.
Còn GRU mới được <a href=http://arxiv.org/pdf/1406.1078v3.pdf target=_blank _ rel="noopener noreferrer">giới thiệu vào năm 2014</a>,
nó là một phiên bản đơn giản hoá của LSTM.
Cả 2 kiến trúc RNN đó được thiết kế để tránh vấn đề mất mát đạo hàm và hiệu quả cho việc học các phụ thuộc xa.
Giờ tôi sẽ dừng bài viết tại đây để dành phần giới thiệu 2 kiến trúc đó ở bài viết sau.</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small">THẺ ĐÁNH DẤU</span><br><a class="tag tag--primary tag--small" href=https://dominhhai.github.io/vi/tags/rnn/>RNN</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/implement-gru-lstm/ data-tooltip="[RNN] Cài đặt GRU/LSTM"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml">Tiếp</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/implement-rnn-with-python/ data-tooltip="[RNN] Cài đặt RNN với Python và Theano"><span class="hide-xs hide-sm text-small icon-mr">Trước</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-google-plus"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#fb-cmt-thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#table-of-contents><i class="fa fa-list"></i></a></li></ul></div><div id=fb-root></div><script>(function(d,s,id){if(window.location.hostname=='localhost')return;var js,fjs=d.getElementsByTagName(s)[0];if(d.getElementById(id))return;js=d.createElement(s);js.id=id;js.src='https://connect.facebook.net/vi_VN/sdk.js#xfbml=1&version=v3.1&appId=333198270561466&autoLogAppEvents=1';fjs.parentNode.insertBefore(js,fjs);}(document,'script','facebook-jssdk'));</script><div id=fb-cmt-thread class=fb-comments data-href=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/ data-width=100%></div></div></article><footer id=footer class=main-content-wrap><div id=helpinfo><div id=author><label id=home>Hai's Blog</label><div class=language><label for=language>Other Languages:</label>
<select id=language>
<option title="Tiếng Việt" value=vi selected>Tiếng Việt (vi)</option>
<option title=English value=en-us>English (en-us)</option>
<option title=日本語 value=ja>日本語 (ja)</option></select></div></div><div id=topic><label>Chủ đề</label><ul><li><a href=https://dominhhai.github.io/vi/categories/l%E1%BA%ADp-tr%C3%ACnh/>Lập Trình</a></li><li><a href=https://dominhhai.github.io/vi/categories/h%E1%BB%8Dc-m%C3%A1y/>Học Máy</a></li><li><a href=https://dominhhai.github.io/vi/categories/to%C3%A1n/>Toán</a></li><li><a href=https://dominhhai.github.io/vi/categories/x%C3%A1c-su%E1%BA%A5t/>Xác Suất</a></li><li><a href=https://dominhhai.github.io/vi/categories/s%C3%A1ch/>Sách</a></li></ul></div><div id=contact><label>Liên hệ</label><ul><li><a href=https://github.com/dominhhai/dominhhai.github.io/issues/new target=_blank><i class="fa fa-lg fa-inbox"></i>Gửi tin nhắn</a></li><li id=follow><a href=https://github.com/dominhhai target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i></a><a href=https://twitter.com/minhhai3b target=_blank><i class="sidebar-button-icon fa fa-lg fa-twitter"></i></a></li></ul></div></div><div id=contentinfo><span class=copyrights>&copy; 2021 <a href=https://github.com/dominhhai>Do Minh Hai</a>. All Rights Reserved</span></div></footer></div><div id=bottom-bar class=post-bottom-bar data-behavior=5><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/implement-gru-lstm/ data-tooltip="[RNN] Cài đặt GRU/LSTM"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml">Tiếp</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2017/10/implement-rnn-with-python/ data-tooltip="[RNN] Cài đặt RNN với Python và Theano"><span class="hide-xs hide-sm text-small icon-mr">Trước</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=https://dominhhai.github.io/vi/2017/10/understand-rnn-bptt/"><i class="fa fa-google-plus"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#fb-cmt-thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#table-of-contents><i class="fa fa-list"></i></a></li></ul></div></div><div id=share-options-bar class=share-options-bar data-behavior=5><i id=btn-close-shareoptions class="fa fa-close"></i><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2017%2F10%2Funderstand-rnn-bptt%2F"><i class="fa fa-facebook-official"></i><span>Chia sẻ với Facebook</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2017%2F10%2Funderstand-rnn-bptt%2F"><i class="fa fa-twitter"></i><span>Chia sẻ với Twitter</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://plus.google.com/share?url=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2017%2F10%2Funderstand-rnn-bptt%2F"><i class="fa fa-google-plus"></i><span>Chia sẻ với Google&#43;</span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=110" alt="Ảnh đại diện"><h4 id=about-card-name>Do Minh Hai</h4><div id=about-card-bio>Just a developer<br>Enjoy life as a journey</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Freelancer</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Japan</div></div></div><div id=cover style=background-image:url(https://dominhhai.github.io/images/cover-v1.2.0.jpg)></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin=anonymous></script><script src=https://dominhhai.github.io/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js></script><script crossorigin=anonymous integrity=sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js></script><script crossorigin=anonymous integrity=sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/contrib/auto-render.min.js></script><script src=https://dominhhai.github.io/js/main.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight > code, pre > code').each(function(i,block){if(!$(this).hasClass('codeblock')){$(this).addClass('codeblock');}
hljs.highlightBlock(block);});});</script><script>var disqus_config=function(){this.page.url='https:\/\/dominhhai.github.io\/vi\/2017\/10\/understand-rnn-bptt\/';this.page.identifier='\/vi\/2017\/10\/understand-rnn-bptt\/'};(function(){if(window.location.hostname=="localhost"){return;}
var d=document,s=d.createElement('script');var disqus_shortname='tranquilpeak';s.src='//'+disqus_shortname+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><script>if(typeof fnMain==='function'){fnMain();}</script></body></html>