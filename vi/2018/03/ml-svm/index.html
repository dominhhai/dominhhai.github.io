<!doctype html><html lang=vi><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.54.0 with theme Tranquilpeak 0.4.1-BETA"><title>[ML] Support Vector Machine - SVM</title><meta name=author content="Do Minh Hai"><meta name=keywords content="Học Máy,Machine Learning,SVM,kernel method,dominhhai,programming,computer science,machine learning,deep learning"><link rel=icon href=https://dominhhai.github.io/favicon/golden-buddha-512-79567.png><link rel=canonical href=https://dominhhai.github.io/vi/2018/03/ml-svm/><meta name=description content="Support Vector Machine - SVM là một phương pháp học có giám sát trong các mô hình nhận dạng mẫu. Nó không chỉ hoạt động tốt với các dữ liệu được phân tách tuyến tính mà còn tốt với cả dữ liệu phân tách phi tuyến. Với nhiều bài toán, SVM mang lại kết quả tốt như mạng nơ-ron với hiệu quả sử dụng tài nguyên tốt hơn hẳn."><link rel=publisher href=https://plus.google.com/115106277658014197977><meta property=fb:app_id content=333198270561466><meta property=og:locale content=vi_VN><meta property=og:type content=article><meta property=article:author content=dominhai><meta property=og:title content="[ML] Support Vector Machine - SVM"><meta property=og:url content=https://dominhhai.github.io/vi/2018/03/ml-svm/><meta property=og:description content="Support Vector Machine - SVM là một phương pháp học có giám sát trong các mô hình nhận dạng mẫu. Nó không chỉ hoạt động tốt với các dữ liệu được phân tách tuyến tính mà còn tốt với cả dữ liệu phân tách phi tuyến. Với nhiều bài toán, SVM mang lại kết quả tốt như mạng nơ-ron với hiệu quả sử dụng tài nguyên tốt hơn hẳn."><meta property=og:site_name content="Hai's Blog"><meta property=og:image content=https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png><meta property=og:image content="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=640"><meta name=twitter:creator content=@minhhai3b><meta name=twitter:card content=summary><meta name=twitter:title content="[ML] Support Vector Machine - SVM"><meta name=twitter:url content=https://dominhhai.github.io/vi/2018/03/ml-svm/><meta name=twitter:description content="Support Vector Machine - SVM là một phương pháp học có giám sát trong các mô hình nhận dạng mẫu. Nó không chỉ hoạt động tốt với các dữ liệu được phân tách tuyến tính mà còn tốt với cả dữ liệu phân tách phi tuyến. Với nhiều bài toán, SVM mang lại kết quả tốt như mạng nơ-ron với hiệu quả sử dụng tài nguyên tốt hơn hẳn."><meta name=twitter:image content="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=640"><meta name=twitter:image content=https://res.cloudinary.com/dominhhai/image/upload/dl/logo.png><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin=anonymous><link rel=stylesheet href=https://dominhhai.github.io/css/style-jsjn0006wyhpyzivf6yceb31gvpjatbcs3qzjvlumobfnugccvobqwxnnaj8.min.css><link rel=stylesheet crossorigin=anonymous href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css integrity=sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei><link rel=stylesheet href=https://dominhhai.github.io/css/main.css><script async src="https://www.googletagmanager.com/gtag/js?id=UA-105333519-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)};gtag('js',new Date());gtag('config','UA-105333519-1');</script></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=https://dominhhai.github.io/vi/>Hai&#39;s Blog</a></div><a class=header-right-picture href=https://dominhhai.github.io/#about><img class=header-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=90" alt="Ảnh đại diện"></a></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=https://dominhhai.github.io/#about><img class=sidebar-profile-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=110" alt="Ảnh đại diện"></a><h4 class=sidebar-profile-name>Do Minh Hai</h4><h5 class=sidebar-profile-bio>Just a developer<br>Enjoy life as a journey</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/><i class="sidebar-button-icon fa fa-lg fa-home"></i><span class=sidebar-button-desc>Trang chủ</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/categories/><i class="sidebar-button-icon fa fa-lg fa-bookmark"></i><span class=sidebar-button-desc>Danh mục</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/tags/><i class="sidebar-button-icon fa fa-lg fa-tags"></i><span class=sidebar-button-desc>Thẻ thông tin</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/archives/><i class="sidebar-button-icon fa fa-lg fa-archive"></i><span class=sidebar-button-desc>Lưu trữ</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/talk/><i class="sidebar-button-icon fa fa-lg fa-child"></i><span class=sidebar-button-desc>Chém gió</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/page/why/><i class="sidebar-button-icon fa fa-lg fa-question"></i><span class=sidebar-button-desc>Hỏi ngu</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/dominhhai target=_blank rel=noopener><i class="sidebar-button-icon fa fa-lg fa-github"></i><span class=sidebar-button-desc>GitHub</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://twitter.com/minhhai3b target=_blank rel=noopener><i class="sidebar-button-icon fa fa-lg fa-twitter"></i><span class=sidebar-button-desc>Twitter</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dominhhai.github.io/vi/index.xml><i class="sidebar-button-icon fa fa-lg fa-rss"></i><span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div id=main data-behavior=5 class=hasCoverMetaIn><article class=post itemscope itemtype=http://schema.org/BlogPosting><div class="post-header main-content-wrap text-center"><h1 class=post-title itemprop=headline>[ML] Support Vector Machine - SVM</h1><div class="postShorten-meta post-meta"><time itemprop=datePublished datetime=2018-03-22T10:20:14&#43;09:00>22 tháng 3, 2018</time>
<span>mục</span>
<a class=category-link href=https://dominhhai.github.io/vi/categories/h%e1%bb%8dc-m%c3%a1y>Học Máy</a>,
<a class=category-link href=https://dominhhai.github.io/vi/categories/ml>ML</a></div></div><div class="post-content markdown" itemprop=articleBody><div class=main-content-wrap><p>Support Vector Machine - <strong>SVM</strong> là một phương pháp học có giám sát trong các mô hình nhận dạng mẫu. Nó không chỉ hoạt động tốt với các dữ liệu được phân tách tuyến tính mà còn tốt với cả dữ liệu phân tách phi tuyến. Với nhiều bài toán, SVM mang lại kết quả tốt như mạng nơ-ron với hiệu quả sử dụng tài nguyên tốt hơn hẳn.</p><h1 id=table-of-contents>Mục lục</h1><nav id=TableOfContents><ul><li><a href=#1-phương-pháp-svm>1. Phương pháp SVM</a></li><li><a href=#2-dữ-liệu-chồng-nhau-và-phương-pháp-biên-mềm>2. Dữ liệu chồng nhau và phương pháp biên mềm</a></li><li><a href=#3-dữ-liệu-phân-tách-phi-tuyến-và-phương-pháp-kernel>3. Dữ liệu phân tách phi tuyến và phương pháp kernel</a></li><li><a href=#4-kết-luận>4. Kết luận</a></li></ul></nav><h1 id=1-phương-pháp-svm>1. Phương pháp SVM</h1><p>Như đã biết, với bài toán phân loại nhị phân tuyến tính ta cần vẽ được mặt phân tách (với không gian 2 chiều thì mặt phẳng này là đường phân tách): $\mathbf{w}^{\intercal}\mathbf{x}+b=0$ để phân biệt được dữ liệu. Khi đó dấu của hàm ước lượng $H=\{\mathbf{x} \mapsto\mathrm{sgn}(\mathbf{w}^{\intercal}\mathbf{x}+b)~~~;\mathbf{w}\in\mathbb{R}^N,b\in\mathbb{R}\}$ sẽ thể hiện được điểm dữ liệu $\mathbf{x}$ nằm ở cụm dữ liệu nào.</p><div class="figure center"><a class=fancybox href=https://dominhhai.github.io/images/ml-20180322-svm_1.svg title="Mặt phân cách dữ liệu" data-fancybox-group><img class=fig-img src=https://dominhhai.github.io/images/ml-20180322-svm_1.svg style=width:100% alt="Mặt phân cách dữ liệu"></a>
<span class=caption>Mặt phân cách dữ liệu</span></div><p>Nếu để ý thì ta có thể có nhiều mặt phân tách thoả mãn được việc này và đương nhiên là nếu chọn được mặt mà phân tách tốt thì kết quả phân loại của ta sẽ tốt hơn. Một lẽ rất tự nhiên là dường như mặt nằm vừa khít giữa 2 cụm dữ liệu sao cho nằm xa các tập dữ liệu nhất là mặt tốt nhất.</p><div class="figure center"><a class=fancybox href=https://dominhhai.github.io/images/ml-20180322-svm_2.svg title="Max Margin" data-fancybox-group><img class=fig-img src=https://dominhhai.github.io/images/ml-20180322-svm_2.svg style=width:100% alt="Max Margin"></a>
<span class=caption>Max Margin</span></div><p><strong>SVM</strong> chính là một biện pháp để thực hiện được phép lấy mặt phẳng như vậy.</p><p>Để xác định mặt phẳng kẹp giữa đó, trước tiên ta cần phải xác định được 2 mặt biên gốc như 2 đường nét đứt ở trên. Các điểm dữ liệu gần với mặt biên gốc này nhất có thể xác định bằng:</p><p>$$\min{\vert\mathbf{w}^{\intercal}\mathbf{x}+b\vert}$$</p><p>Để dễ dàng cho việc tính toán thì người ta sẽ chọn $\mathbf{w}$ và $b$ sao cho các điểm gần nhất (mặt biên gốc) thoả mãn: $\vert\mathbf{w}^{\intercal}\mathbf{x}+b\vert=1$, tức là:
$$\min{\vert\mathbf{w}^{\intercal}\mathbf{x}+b\vert}=1$$</p><p>Đương nhiên là có thể tồn tại nhiều cặp đôi mặt biên gốc như vậy và tồn tại nhiều mặt phân đôi kẹp giữa các mặt biên gốc đó. Nên ta phải tìm cách xác định được mặt kẹp giữa tốt nhất bằng cách lấy cặp có khoảng cách xa nhau nhất. Lẽ này là đương nhiên bởi cặp có khoảng cách xa nhất đồng nghĩa với chuyện tập dữ liệu được phân cách xa nhất.</p><p>Như vậy, ta có thể thiết lập thông số tính khoảng cách đó bằng phép lấy độ rộng biên từ mặt biên gốc tới mặt phân tách cần tìm.
$$\rho=\min\dfrac{\vert\mathbf{w}^{\intercal}\mathbf{x}+b\vert}{\Vert\mathbf{w}\Vert}=\dfrac{1}{\Vert\mathbf{w}\Vert}$$</p><p>Bài toán của ta bây giờ sẽ là cần xác định $\mathbf{w}$ và $b$ sao cho $\rho$ đạt lớn nhất và các điểm dữ liệu $y_i(\mathbf{w}^{\intercal}\mathbf{x}_i+b)\ge 1$. $\rho$ đạt lớn nhất đồng nghĩa với việc $\Vert\mathbf{w}\Vert$ đạt nhỏ nhất. Tức là:
$$
\begin{aligned}
(\mathbf{w},b)&amp;=\arg\min_{\mathbf{w},b}\frac{1}{2}\Vert\mathbf{w}\Vert^2
\cr
\text{subject to}~~~&amp;y_i(\mathbf{w}^{\intercal}\mathbf{x}_i+b)\ge 1, i\in[1,m]
\end{aligned}
$$</p><p>Ở đây, $m$ là số lượng các điểm dữ liệu $(\mathbf{x}_i,y_i)$ còn việc lấy bình phương và chia đôi nhằm dễ dàng tính toán và tối ưu lồi.</p><p>Bài toán này có thể giải thông qua bài toán đối ngẫu của nó và sử dụng phương pháp <a href=https://dominhhai.github.io/vi/2018/02/lagrange-multipliers-2/>nhân tử Lagrance</a>. Lúc này, ta sẽ cần tìm các giá trị $\lambda$ như sau:
$$
\begin{aligned}
\lambda&amp;=\arg\max_\lambda\sum_{i=1}^m\lambda_i-\frac{1}{2}\sum_{i,j=1}^m\lambda_i\lambda_jy_iy_j\mathbf{x}_i^{\intercal}\mathbf{x}_j
\cr
\text{subject to}~~~&amp;\lambda_i\ge 0 \land \sum_{i=1}^m\lambda_iy_i=0, i\in[1,m]
\end{aligned}
$$</p><p>Việc giải $\lambda$ có thể được thực hiện bằng phương pháp quy hoạch động bậc 2 (<em>Quadratic Programing</em>). Với Python ta có thể sử dụng thư viện <a href=http://cvxopt.org/examples/tutorial/qp.html target=_blank _ rel="noopener noreferrer">CVOPT</a>. Sau khi tìm được $\lambda$ thì ta có các tham số:
$$
\begin{aligned}
\mathbf{w}&amp;=\sum_{i=1}^m\lambda_iy_i\mathbf{x}_i
\cr
b&amp;=y_i-\sum_{j=1}^m\lambda_jy_j\mathbf{x}_j^{\intercal}\mathbf{x}_i
\end{aligned}
$$</p><p>Ở đây, $(\mathbf{x}_i, y_i)$ là một điểm dữ liệu bất kì nào đó nằm trên đường biên gốc. Điểm dữ liệu này còn được gọi là <strong>Support Vector</strong>. Tên của phương pháp SVM cũng từ đây mà ra. Tuy nhiên, thường người ta tính $b$ bằng phép lấy trung bình tổng của tất cả các $b_i$. Giả sử, ta có tập $\mathbb{S}$ các Support Vectors thì:
$$b=\frac{1}{\vert \mathbb{S}\vert}\sum_{i\in\mathbb{S}}\Bigg(y_i-\sum_{j=1}^m\lambda_jy_j\mathbf{x}_j^{\intercal}\mathbf{x}_i\Bigg)$$</p><p>Khi đó, một điểm dữ liệu mới sẽ được phân loại dựa theo:
$$h(\mathbf{x})=\mathrm{sgn}\Bigg(\sum_{i=1}^m\lambda_iy_i\mathbf{x_i}^{\intercal}\mathbf{x}+b\Bigg)$$</p><p>Như vậy, chỉ cần các điểm Support Vector trên đường biên gốc là ta có thể ước lượng được các tham số tối ưu cho bài toán. Việc này rất có lợi khi tính toán giúp phương pháp này tiết kiệm được tài nguyên thực thi.</p><h1 id=2-dữ-liệu-chồng-nhau-và-phương-pháp-biên-mềm>2. Dữ liệu chồng nhau và phương pháp biên mềm</h1><p>Trong thực tế tập dữ liệu thường không được sạch như trên mà thường có nhiễu. Nhiễu ở đây là dạng dữ liệu chồng chéo lên nhau như hình bên dưới.</p><div class="figure center"><a class=fancybox href=https://dominhhai.github.io/images/ml-20180322-svm_3.svg title="Non-linear data" data-fancybox-group><img class=fig-img src=https://dominhhai.github.io/images/ml-20180322-svm_3.svg style=width:100% alt="Non-linear data"></a>
<span class=caption>Non-linear data</span></div><p>Với dạng dữ liệu như vậy thì mặt phân tách tìm được sẽ khó mà tối ưu được, thậm chí là không tìm được mặt phân tách luôn. Giờ vấn đề đặt ra là làm sao triệt được các nhiễu này. Tức là tính toán bỏ qua được các nhiễu này khi huấn luyện.</p><p>Một cách hình thức, các điểm nhiễu là những điểm mà không đảm bảo điều kiện $y_i(\mathbf{w}^{\intercal}\mathbf{x}+b)\ge 1$. Khi đó bằng phép thêm biến lùi (<em>Slack Variables</em>) $\xi_i\ge 0$ sao cho ra có được ràng buộc:
$$y_i(\mathbf{w}^{\intercal}\mathbf{x}+b)\ge 1-\xi_i$$</p><p>Giờ, hàm mục tiêu tối ưu được viết lại như sau:
$$
\begin{aligned}
(\mathbf{w},b,\xi)&amp;=\arg\min_{\mathbf{w},b}\frac{1}{2}\Vert\mathbf{w}\Vert^2 + C\sum_{i=1}^m\xi_i
\cr
\text{subject to}~~~&amp;\xi_i\ge 0 \land y_i(\mathbf{w}^{\intercal}\mathbf{x}_i+b)\ge 1-\xi_i ~~~, i\in[1,m]
\end{aligned}
$$</p><p>$C$ ở đây là hệ số cân bằng giữa nhiễu và không nhiễu. Nếu $C$ càng lớn thì các nhiễu càng nhiều điểm được coi là nhiễu hơn tức là nhiễu được coi trọng hơn.</p><p>Giải bài toán này, nghiệm tương tự như cách tính ở trên chỉ khác một điều là tập các điểm support vectors $\mathbb{S}$ được mở rộng thêm tới các điểm $(\mathbf{x}_i,y_i)$ ra miễn sao nó thoả mãn điều kiện:
$$0&lt;\lambda_i&lt;C$$</p><p>Tức là:
$$
\begin{aligned}
\lambda&amp;=\arg\max_\lambda\sum_{i=1}^m\lambda_i-\frac{1}{2}\sum_{i,j=1}^m\lambda_i\lambda_jy_iy_j\mathbf{x}_i^{\intercal}\mathbf{x}_j
\cr
\text{subject to}~~~&amp;0\le\lambda_i\le C \land \sum_{i=1}^m\lambda_iy_i=0, i\in[1,m]
\end{aligned}
$$</p><p>Khi đó, tham số được ước lượng như sau:
$$
\begin{aligned}
\mathbf{w}&amp;=\sum_{i=1}^m\lambda_iy_i\mathbf{x}_i
\cr
b&amp;=\frac{1}{\vert \mathbb{S}\vert}\sum_{i\in\mathbb{S}}\Bigg(y_i-\sum_{j=1}^m\lambda_jy_j\mathbf{x}_j^{\intercal}\mathbf{x}_i\Bigg) ~~~\text{for }x_i\text{ with } 0&lt;\lambda_i&lt;C
\end{aligned}
$$</p><p>Với tập $\mathbb{S}$ mở rộng như vậy người ta gọi phương pháp này là phương pháp biên mềm (<strong>Soft-Margin SVM</strong>). Còn phương pháp truyền thống là biên cứng (<strong>Hard-Margin SVM</strong>).</p><h1 id=3-dữ-liệu-phân-tách-phi-tuyến-và-phương-pháp-kernel>3. Dữ liệu phân tách phi tuyến và phương pháp kernel</h1><p>Như các bài trước đã đề cập tới việc sử dụng hàm cơ bản $\Phi(\mathbf{x})$ để tạo đặc trưng cho tập dữ liệu nhằm nâng được chiều của dữ liệu ban đầu. Bằng các hàm cơ bản này, ta có thể tạo các mặt cong phân tách cho phù hợp với các điểm dữ liệu không phân tách tuyến tính.</p><p>Khi đó tối ưu biên mềm được viết dưới dạng:
$$
\begin{aligned}
\lambda&amp;=\arg\max_\lambda\sum_{i=1}^m\lambda_i-\frac{1}{2}\sum_{i,j=1}^m\lambda_i\lambda_jy_iy_j\Phi(\mathbf{x}_i)^{\intercal}\Phi(\mathbf{x}_j)
\cr
\text{subject to}~~~&amp;0\le\lambda_i\le C \land \sum_{i=1}^m\lambda_iy_i=0, i\in[1,m]
\end{aligned}
$$</p><p>Đặt hàm <strong>Kernel</strong> $K(\mathbf{x}_i,\mathbf{x}_j)=\Phi(\mathbf{x}_i)^{\intercal}\Phi(\mathbf{x}_j)$, ta có:</p><p>$$
\begin{aligned}
\lambda&amp;=\arg\max_\lambda\sum_{i=1}^m\lambda_i-\frac{1}{2}\sum_{i,j=1}^m\lambda_i\lambda_jy_iy_jK(\mathbf{x}_i,\mathbf{x}_j)
\cr
\text{subject to}~~~&amp;0\le\lambda_i\le C \land \sum_{i=1}^m\lambda_iy_i=0, i\in[1,m]
\end{aligned}
$$</p><p>Khi đó tham số tương ứng sẽ là:
$$
\begin{aligned}
\mathbf{w}&amp;=\sum_{i=1}^m\lambda_iy_i\Phi(\mathbf{x}_i)
\cr
b&amp;=\frac{1}{\vert \mathbb{S}\vert}\sum_{i\in\mathbb{S}}\Bigg(y_i-\sum_{j=1}^m\lambda_jy_jK(\mathbf{x}_i,\mathbf{x}_j)\Bigg) ~~~\text{for }x_i\text{ with } 0&lt;\lambda_i&lt;C
\end{aligned}
$$</p><p>Điểm dữ liệu mới được phân lớp với:
$$h(\mathbf{x})=\mathrm{sgn}\Bigg(\sum_{i=1}^m\lambda_iy_i\Phi(\mathbf{x_i})^{\intercal}\Phi(\mathbf{x})+b\Bigg)=\mathrm{sgn}\Bigg(\sum_{i=1}^m\lambda_iy_iK(\mathbf{x}_i,\mathbf{x})+b\Bigg)$$</p><p>Như vậy, chỉ cần hàm Kernel $K(\mathbf{x}_i,\mathbf{x}_j)$ để tính tích vô hướng giữa các điểm dữ liệu trong không gian mới là ta có thể ước lượng được một điểm mới nằm trong phân lớp nào.</p><p>Việc sử dụng hàm Kernel ở đây sẽ giúp giảm được công số tính từng hàm $\Phi$ và tích vô hướng giữa chúng. Nó có thể tính được cho bất kì không gian nào rất hiệu quả. Kể cả các không gian với số chiều vô hạn. Bởi nó chỉ cần tính tích vô hương giữa các điểm dữ liệu mà thôi. Tất nhiên để làm được điều đó thì Kernel phải thoả mãn <a href=https://en.wikipedia.org/wiki/Mercer%27s_theorem#Mercer.27s_condition target=_blank _ rel="noopener noreferrer">điều kiện Mercer</a>.</p><p>Khi làm việc người ta thường chọn một hàm Kernel thông dụng sau:</p><table><thead><tr><th>Hàm</th><th>Công thức</th></tr></thead><tbody><tr><td>Đa thức (<em>Polynomial Kernels</em>)</td><td>$K(x,y)=(x^{\intercal}y+c)^d ~~~, c&gt;0, \forall{x,y\in\mathbb{R}^n}$</td></tr><tr><td>Gaoxo (Gaussian Kernels)</td><td>$K(x,y)=\exp\Bigg(-\dfrac{\Vert x-y\Vert^2}{2\sigma^2}\Bigg) ~~~, \forall{x,y\in\mathbb{R}^n}$</td></tr><tr><td>Sigmoid (Sigmoid Kernels)</td><td>$K(x,y)=\tanh(ax^{\intercal}y+b) ~~~,a,b\ge 0, \forall{x,y\in\mathbb{R}^n}$</td></tr></tbody></table><h1 id=4-kết-luận>4. Kết luận</h1><p>Phương pháp SVM là một cách hiệu quả cho bài toán phân lớp mà chỉ sử dụng một lượng ít dữ liệu là các điểm support vectors nằm trên đường biên gốc và phần mở rộng. Giả sử $\mathbb{S}$ là tập các điểm support vectors, ta cần tìm $\lambda$ như sau:
$$
\begin{aligned}
\lambda&amp;=\arg\max_\lambda\sum_{i=1}^m\lambda_i-\frac{1}{2}\sum_{i,j=1}^m\lambda_i\lambda_jy_iy_jK(\mathbf{x}_i,\mathbf{x}_j)
\cr
\text{subject to}~~~&amp;0\le\lambda_i\le C \land \sum_{i=1}^m\lambda_iy_i=0, i\in[1,m]
\end{aligned}
$$</p><p>Và hàm đánh giá điểm dữ liệu mới được thể hiện:
$$h(\mathbf{x})=\mathrm{sgn}\Bigg(\sum_{i=1}^m\lambda_iy_iK(\mathbf{x}_i,\mathbf{x})+b\Bigg)$$</p><p>Trong đó $K(\mathbf{x}_i,\mathbf{x}_j)$ là hàm Kernel thoả mãn điều kiện <a href=https://en.wikipedia.org/wiki/Mercer%27s_theorem#Mercer.27s_condition target=_blank _ rel="noopener noreferrer">điều kiện Mercer</a>. Nếu hàm Kernel là một hàm tuyến tính thì ta có thể coi là giữ nguyên không gian dữ liệu ban đầu, còn không ta có thể nghĩ rằng ta đang chiếu các điểm dữ liệu qua một không gian có số chiều lớn hơn.</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small">THẺ ĐÁNH DẤU</span><br><a class="tag tag--primary tag--small" href=https://dominhhai.github.io/vi/tags/h%E1%BB%8Dc-m%C3%A1y/>Học Máy</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2018/04/git-clone-tag/ data-tooltip="[Git] Lấy mã nguồn theo tag"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml">Tiếp</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2018/03/py-venv/ data-tooltip="[Python] Cài đặt môi trường ảo"><span class="hide-xs hide-sm text-small icon-mr">Trước</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=https://dominhhai.github.io/vi/2018/03/ml-svm/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dominhhai.github.io/vi/2018/03/ml-svm/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=https://dominhhai.github.io/vi/2018/03/ml-svm/"><i class="fa fa-google-plus"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#fb-cmt-thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#table-of-contents><i class="fa fa-list"></i></a></li></ul></div><div id=fb-root></div><script>(function(d,s,id){if(window.location.hostname=='localhost')return;var js,fjs=d.getElementsByTagName(s)[0];if(d.getElementById(id))return;js=d.createElement(s);js.id=id;js.src='https://connect.facebook.net/vi_VN/sdk.js#xfbml=1&version=v3.1&appId=333198270561466&autoLogAppEvents=1';fjs.parentNode.insertBefore(js,fjs);}(document,'script','facebook-jssdk'));</script><div id=fb-cmt-thread class=fb-comments data-href=https://dominhhai.github.io/vi/2018/03/ml-svm/ data-width=100%></div></div></article><footer id=footer class=main-content-wrap><div id=helpinfo><div id=author><label id=home>Hai's Blog</label><div class=language><label for=language>Other Languages:</label>
<select id=language>
<option title="Tiếng Việt" value=vi selected>Tiếng Việt (vi)</option>
<option title=English value=en-us>English (en-us)</option>
<option title=日本語 value=ja>日本語 (ja)</option></select></div></div><div id=topic><label>Chủ đề</label><ul><li><a href=https://dominhhai.github.io/vi/categories/l%E1%BA%ADp-tr%C3%ACnh/>Lập Trình</a></li><li><a href=https://dominhhai.github.io/vi/categories/h%E1%BB%8Dc-m%C3%A1y/>Học Máy</a></li><li><a href=https://dominhhai.github.io/vi/categories/to%C3%A1n/>Toán</a></li><li><a href=https://dominhhai.github.io/vi/categories/x%C3%A1c-su%E1%BA%A5t/>Xác Suất</a></li><li><a href=https://dominhhai.github.io/vi/categories/s%C3%A1ch/>Sách</a></li></ul></div><div id=contact><label>Liên hệ</label><ul><li><a href=https://github.com/dominhhai/dominhhai.github.io/issues/new target=_blank><i class="fa fa-lg fa-inbox"></i>Gửi tin nhắn</a></li><li id=follow><a href=https://github.com/dominhhai target=_blank><i class="sidebar-button-icon fa fa-lg fa-github"></i></a><a href=https://twitter.com/minhhai3b target=_blank><i class="sidebar-button-icon fa fa-lg fa-twitter"></i></a></li></ul></div></div><div id=contentinfo><span class=copyrights>&copy; 2021 <a href=https://github.com/dominhhai>Do Minh Hai</a>. All Rights Reserved</span></div></footer></div><div id=bottom-bar class=post-bottom-bar data-behavior=5><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2018/04/git-clone-tag/ data-tooltip="[Git] Lấy mã nguồn theo tag"><i class="fa fa-angle-left"></i><span class="hide-xs hide-sm text-small icon-ml">Tiếp</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dominhhai.github.io/vi/2018/03/py-venv/ data-tooltip="[Python] Cài đặt môi trường ảo"><span class="hide-xs hide-sm text-small icon-mr">Trước</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions><i class="fa fa-share-alt"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.facebook.com/sharer/sharer.php?u=https://dominhhai.github.io/vi/2018/03/ml-svm/"><i class="fa fa-facebook-official"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dominhhai.github.io/vi/2018/03/ml-svm/"><i class="fa fa-twitter"></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://plus.google.com/share?url=https://dominhhai.github.io/vi/2018/03/ml-svm/"><i class="fa fa-google-plus"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#fb-cmt-thread><i class="fa fa-comment-o"></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#table-of-contents><i class="fa fa-list"></i></a></li></ul></div></div><div id=share-options-bar class=share-options-bar data-behavior=5><i id=btn-close-shareoptions class="fa fa-close"></i><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2018%2F03%2Fml-svm%2F"><i class="fa fa-facebook-official"></i><span>Chia sẻ với Facebook</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2018%2F03%2Fml-svm%2F"><i class="fa fa-twitter"></i><span>Chia sẻ với Twitter</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://plus.google.com/share?url=https%3A%2F%2Fdominhhai.github.io%2Fvi%2F2018%2F03%2Fml-svm%2F"><i class="fa fa-google-plus"></i><span>Chia sẻ với Google&#43;</span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-remove"></i></div><img id=about-card-picture src="https://www.gravatar.com/avatar/711b36be8e444cd1d60b348077bfd752?s=110" alt="Ảnh đại diện"><h4 id=about-card-name>Do Minh Hai</h4><div id=about-card-bio>Just a developer<br>Enjoy life as a journey</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>Freelancer</div><div id=about-card-location><i class="fa fa-map-marker"></i><br>Japan</div></div></div><div id=cover style=background-image:url(https://dominhhai.github.io/images/cover-v1.2.0.jpg)></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin=anonymous></script><script src=https://dominhhai.github.io/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js></script><script crossorigin=anonymous integrity=sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js></script><script crossorigin=anonymous integrity=sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/contrib/auto-render.min.js></script><script src=https://dominhhai.github.io/js/main.js></script><script>$(document).ready(function(){hljs.configure({classPrefix:'',useBR:false});$('pre.code-highlight > code, pre > code').each(function(i,block){if(!$(this).hasClass('codeblock')){$(this).addClass('codeblock');}
hljs.highlightBlock(block);});});</script><script>var disqus_config=function(){this.page.url='https:\/\/dominhhai.github.io\/vi\/2018\/03\/ml-svm\/';this.page.identifier='\/vi\/2018\/03\/ml-svm\/'};(function(){if(window.location.hostname=="localhost"){return;}
var d=document,s=d.createElement('script');var disqus_shortname='tranquilpeak';s.src='//'+disqus_shortname+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><script>if(typeof fnMain==='function'){fnMain();}</script></body></html>